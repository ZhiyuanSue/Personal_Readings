这篇文章是OSDI23的文章，大概讲的就是在NUMA环境下如何在不同的核心之间传递自旋锁



# Introduction

Cache Coherent Non-uniform Memory Access

ccNUMA

程序使用Spinlock和atomic来保证一致性，并在临界区访问共享数据。



但是，不同NUMA系统的拓扑结构并不相同

而这导致了，对于NUMA系统进行扩展的困难性



说了一大堆话（感觉就是现状）



介绍了本文的贡献

提出单向最短循环路由

对于现代处理器来说，仅仅是长期公平是不够的





# 背景

## ccNUMA的一致性

看这个图一

使用基于snoop和基于目录的方法进行一致性的维护

前者是广播

后者是点对点



## 多核CPU上自旋锁的成本

成本包括争用和交接

### 争用是确定下一个进入CS的CPU的时间

例如ticket lock是中心化的，但是MCR自旋锁是去中心化的

在前者中，ticket lock因为是中心化的，所以很多个核心都需要一起监控同一个变量，而且他自旋，所以有很大的流量开销

而GNU的pthread_spin_lock则是MCR，他依赖于NoC确定下一个



### 切换成本，由于使用NUMA来进行数据共享传输

那么和核心跟这个数据副本的距离有一定关系

比如在同一个核心簇上面，成本是1，而距离系统总线较近的共享成本是2，较远的则是3

那么传统的NUMA-aware的自旋锁顺序随意的，按照他给的例子，那么就是10，但是如果最优化的情况，应该是8



目前已经提出的技术

TAS

TTAS（test and test and set）

C-BO-MCS

ShfLock



本文定义了公平性

1、每个任务进入临界区的概率是相同的，每个进入CS的任务的概率在概率上是相同的。

2、有界等待，每个进入CS的任务的概率在概率上是相同的。



在单核处理器中，每个线程获得锁的概率跟他获得的CPU时间比例有关系

这种情况下TTAS满足概率公平性，目前GNU的pthread_spin_lock就是使用TTAS来做的



Ticket和MCR都是按照FIFO做的，但是正如前面的任务所表现的那样，并不是说，FIFO对于ccNUMA访存是最优的

另一个问题是，由于实际上物理制造工艺的差别，有些个别核心可能 实际上获取锁的能力，比其他锁都强。（这在核心数量多的多核处理器上面，是非常正常的）



# 相关工作

首先是GNU的使用TTAS做的自旋锁

他倾向于为相邻的核心提供锁，

缺点很多，

不公平，容易导致饿死等等

延迟是可变的，无法保证延迟

不可扩展性（就是核心数量多了会完蛋）



其他有

cohort，把两个NUMA无关的锁合成一个NUMA-aware的锁，分组进入临界区，降低切换成本

ShfLock/CNA 也试图分组，但是仍然不公平

等等等等。。。



# RON

这个RON的核心思想就是把这个竞争NUMA锁的东西，看做一个这把锁从多个核心进行旅行家算法

但是问题在于，旅行家算法是一个NP完全问题。显然不可能在抢这把锁的时候动态去计算

因此做了一个折中

假定是说，每个核心上面都有一个线程试图抢这把锁

然后根据这个，预先计算出最优的TSP顺序



RON则根据这个最优的TSP顺序，让希望访问的线程一个接一个的进入



为了能够在预先的计算中，找出一个TSP顺序

作者弄了一个基准程序，计算核间延迟

从而得到一个不同核心（类似于图）的全连接加权图



解读一下算法

lock和unlock



总而言之这个例子非常简单



oversubscription

实际上，并不总是一个核心上只有一个线程试图抢这把锁

所以这种情况称为超额订阅

如果2核心4线程（超线程）

那么显然同一个核心上面的内核抢到的概率更大。

但另一种情况则不同，如果所有核心都在一个核心上，下一个运行的线程自然就抢到锁了，所以这时候抢到锁的概率取决于调度器是否公平

如果给RON加上超额订阅功能



之前的RON的wait array表示有多少线程正在等待

而在这里，把每个元素表示该核心上有多少线程正在等待

作者实现了两个算法

RON-ticket和RON-Plock

但都是将这个wait  array的元素替换为了一个struct





1、Plock: GNU Pthread的自旋锁。打算进入CS的线程将测试该锁，直到它的值等于0。当线程离开CS时，它将锁设置为0。第一个观察到锁为0的核心可以进入CS。离核心越近，锁被释放，核心进入CS的可能性越大。 

2、Ticket:此方法允许每个等待进入CS的任务都有一个“Ticket”号码。线程等待，直到“授予”等于它的票号。所有等待线程的等待循环使用原子指令不断地查询“grant”的值，这消耗了有限的NoC带宽。

3、MCS:因为所有等待进入CS的任务都在一个链表中排队，当一个线程离开CS时，它只需要将下一个任务的“等待标志”设置为false。当CPU支持目录缓存一致性算法时，设置下一个线程的等待标志比组播更有效。MCS不能优化多核架构下的互连延迟。

4、C-BO-MCS:线程应该首先获得其所属NUMA节点的MCS锁。然后，它必须与其他NUMA节点上的线程竞争以获得回退锁。如果一个核心与获得C-BO-MCS锁的核心相邻，则该核心具有更高的进入CS的优先级。使用该方法，可以将属于同一节点的线程分组在一起，以减少切换成本。

5、ShflLock(也称为Shuffle Lock):它也使用分组来提高性能。Shuffle可以指定队列中的一个线程负责Shuffle。但是，当允许进入CS的任务正在洗牌队列时，线程不能立即进入CS，可能会降低系统性能。


