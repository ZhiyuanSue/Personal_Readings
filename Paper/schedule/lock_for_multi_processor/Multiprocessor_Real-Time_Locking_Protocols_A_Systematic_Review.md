写在前面：我这边找到了两个名字很像的文档（当初下载的时候也没仔细辨别），认真看了之后，认为两者应该是同一篇文章的不同时间的更改，在此，采取文章中明确说是2018年末的那一个版本，作为阅读的版本。

大概都是综述类的东西。

我觉得应该先看这个综述，了解各种锁协议

（唔，这124页也内容不少，于是我信心满满的去找网易有道的那个AI去读了，至于效果嘛，这不就是个大号翻译软件？？？不是还是得自己看一遍嘛。。。？而且翻译最多50多页，再往后就加载不出来了，乐）



# Introduction

说，单处理器的实时同步问题已经被充分探索过了，但是在多核上面的情况则并非如此，目前（起码这篇文章弄的时候吧，他说是2018年末）仍然没有一个广泛接受的标准协议或者方法

另一个事情是，忽略了细粒度的嵌套问题（就是在持有一个资源的时候去持有另一个资源），尽管在第九章中实现的（不知道是啥算法）能够支持这个问题。

因此还有很多悬而未决的问题。

关于范围限定，限定在共享内存的多处理器的实时锁定协议上（虽然有些地方可以在分布式系统中应用），并且不考虑替代同步策略（例如无锁定和无等待算法，事务内存技术或者其他的提供事务级别中间件的方法），限制在RTOS并且排除了完全静态的计划方法（就是全都计划好了，从而不需要仲裁）



# 多处理器实时锁的问题（就是存在的问题）

首先定义问题，就是，有共享内存的多处理器，有m个相同的处理器内核组成，管理n个任务，每次激活任务称为作业，这些任务共享一些共享资源，比如共享数据结构，os内部结构，io端口等等等等，通过lock和unlock显式获取和释放。

对于目标，是序列化所有资源请求的lock和unlock包围的代码部分，从而满足所有任务的计时约束。必须考虑由于争用的最大阻塞延迟，从而需要考虑使用哪种类型的锁，必须遵循的规则，以及锁和调度器的交互。

对于一些假定，大多数工作都假定，任务通常周期性或者零星的激活模式（我认为他的意思是，某个任务通常会偶尔的被激活），以及任务的时间要求，通常是确定性的（我对此的理解是，这意味着硬实时，而不是软实时），主要原因是，软实时需要考虑更多。

需要知道每个任务最坏的执行时间（WCET，worst-case execution time），每个关键部分的成本和数量，这个关键部分是不包括阻塞延迟的。



关于处理器调度，分区调度（partitioned）的时候，每个任务会静态的分配给某个处理器，每个处理器使用单处理器策略进行调度，例如fixed-priority（FP）固定优先级调度，或者earliest-deadline first（EDF）调度，所以分区的情况下就是P-FP和P-EDF调度了

在全局调度（global）调度，任务可以在任何处理器上执行，也可以在处理器上面迁移。包括G-FP和G-EDF调度，可选择的包括，P公平调度

第三，还有一种簇调度。m个核分为一系列簇，静态的将任务分配到簇上面去，使用全局调度策略在簇上面调度，假设一个簇中又c个core，global，就相当于m=c，分区调度就相当于m个簇和c=1。会更麻烦一点，虽然这个更通用

所以历史上，作者在考虑锁的时候，通常会集中于global或者partitioned 调度。



一个共享资源如果只被同一个cluster或者core所占用，那么他是local的。否则是全局的。

在分区调度中，可以使用一个已知的最优化的单处理器的协议，例如PCP或者SRP

在簇调度中，可以在每个簇中用一个全局的调度方法



所以在本文中，只考虑global的一个调度算法



## 关键设计选择

- 请求顺序问题，任务必须按照一定顺序进行请求，比如FIFO和优先级队列。也有乱序的，但是，有时候不可避免这个问题。

- 自旋锁和挂起的选择，一般来说，短时间用自旋锁，而挂起则用在长时间。

- 优先级反转问题

- 细粒度锁定问题，可能导致死锁和复杂的阻塞效应，一般来说，两阶段锁定和组锁定

- 就地执行，预先指定一个同步处理器来执行所有的于此相关的临界区

对于其他

需要仔细的分析阻塞的问题，这已经有一些特定和通用的框架



在考虑同步约束的情况下，对于一些系统优化问题，可以形式化

比如给定平台和调度策略和一个锁协议，可以决定好如何将任务映射到处理器上面去

资源映射问题，

平台最优化问题（决定最少需要多少个核心）

策略选择问题



# 历史

没啥大不了的，随便记录

分布式优先级上限协议（DPCP）

多处理器优先级上限协议（MPCP)（建议了解）

多处理器堆栈资源策略（MSRP）（建议了解）（后面有提到）

灵活的多处理器锁定协议（FMLP）结合了MSRP和MPCP的许多优点（建议了解），为分区和全局进行了考虑

在这个之后，就有很多论文了



# Progress Mechanisms

反正就是讲一下经典的问题。

先约定好一些规则，使用FP（fixed  priority）固定优先级，按照严格的递减情况（就没有相同优先级的意思），并且使用最简单的挂起锁或者自旋锁，而没有其他的锁协议。

## 单核情况下的优先级反转问题

这个肯定都学过的

分为高中低优先级三个程序

低优先级获取了共享元素的锁，高优先级也想要这个锁，然后低优先级被中优先级抢占了，于是高优先级获取不到这把锁，就超时了。

unbound 优先级反转——因为中优先级的最坏时间（WCET）不确定，所以是unbound

办法有：

优先级继承和优先级天花板协议

优先级继承：

当高优先级请求低优先级的锁的时候，将低优先级的优先级提升到高，等到低优先级离开临界区再降低到原来的情况。

优先级天花板：

当一个进程进入临界区，其优先级就提升到所有可能使用该临界区的最高值。释放临界区之后再回复原来的优先级。



## 多核情况下的优先级反转问题

第一种情况，和单核情况下类似，比如有低和中1，中2，以及高优先级的四个进程在两个核心上面

低获取了锁，中1，中2分别到两个核心上调度并且运行了，那么无论高在哪个核心上面跑，都会被阻塞

更多核心的情况下类似。

第二种情况，同样是低中高三种，低和高在核心1上面，中在核心2上面。

低占用了共享变量，高没有请求共享变量，但是抢占了低，而中在另一个核心上面请求共享变量。

所以从中的角度来说，就被莫名其妙的延迟了。

这主要是在某些分析单处理器的情况下，由于没有考虑到多核对于这个事情的影响，从而造成的问题。

因此，对于优先级翻转这个情况的定义，在多核情况下，不仅仅需要考虑自己单核心的因为抢占和锁问题导致的优先级翻转的情况，还需要考虑多核情况下，在其他核心上通过某种原因导致的本核心上面长时间没有获取共享资源的情况。

对于优先级翻转，在此需要定义为在一个global调度情况下任何会导致m核平台下高优先级的进程等待的情况，都会构成优先级翻转。

全局调度和分区调度的情况都可以这么定义

所以他给了个定义（我不改了直接抄）

```
Def. 1. A job J of task τ i , assigned to a cluster C consisting of c cores, suffers priority-inversion blocking
(pi-blocking) at time t if and only if
1. J is pending (i.e., released and incomplete) at time t,
2. J is not scheduled at time t, and
3. fewer than c equal- or higher-priority jobs of tasks assigned to cluster C are scheduled on processors
belonging to τ i ’s assigned cluster C.
```

这里是用job而不是task。



## Non-Preemptive Sections

最简单的办法是，在持有锁的情况下，拒绝抢占，这样的话，根本不可能被抢占

那么上面多核情况下的第二种情况，在第二个核心上面的中优先级的任务必然会获取到锁，不造成阻塞

不过，这样一来，又造成了高优先级的被低优先级的给翻转了。因为这时候他不允许抢占了。

因此，一个重要的点在于，这不是免费的，必须在等待获取资源的任务和更高优先级之间做出一定的权衡和取舍。



同样的，集群和全局调度的情况下。这种禁止抢占的情形依然是有效的。

但是，这有一定的微妙的地方。

举个例子，在前面的多核情况下的第一种情况中的例子为例，不过现在需要共享数据的进程发生了变化，最低的任务拒绝抢占，然后中1想要这个共享数据，中2并不想，但是在另一个核心上面正常跑，此时，中1会被共享变量所阻塞，但是他可以去抢占在另一个核心上面的中2（尽管抢占了之后仍然会被阻塞）。而中2由于长期获取不到中2跑的这个核心，所以最终会在低跑的核心上面，被高抢占之后，再执行。

所以中1有两个策略，一个是等待低的任务完成，一个是直接抢占另一个核心上的内容（如果另一个核心上的进程优先级更低）

前者被称为lazy preemption（懒惰抢占）或者是link-based global scheduling

后者被称作eager preemption（紧急抢占）



从OS的角度来说，eager是更容易实现的，但是最坏情况下非常糟糕，因为他很有可能反复抢占核心，反复阻塞。

虽然在单核情况下并且没有自动挂起的情况，最多被这样阻塞一次。



而lazy的情况，则是无论如何最多被阻塞一次。

link-based global scheduling，则是在一个基于Linux的实时扩展litmus中被实现。它的名字来源于它在新发布的作业和它应该抢占的非抢占执行作业（如果有的话）之间创建了“链接”;一旦链接的作业退出其非抢占部分，就会立即实施延迟抢占，这可以有效地实现

（我确实觉得这话很绕，我的理解是，一个新的作业，链接了一堆需要他抢占的，但是现在不能抢占掉的作业，如果那些作业的禁止抢占的部分被执行完了，那么就立即执行抢占，他之所以是lazy的，是因为他确实让因为共享条件被阻塞的那些任务，不去抢占别的核心）



对于如何拒绝抢占，在OS中，可以禁用中断，在用户模式中，由于不能禁用中断，所以可以通过为关键任务部分添加一个大于任何优先级的优先级来模拟

但是总而言之有个问题就是，禁用中断对于一些高时间要求的任务容易错过ddl，如果关键部分的任务时间还特别长，那基本gg



## 优先级继承

在单处理器情形下，优先级继承和优先级上限协议已经解决了这个问题，但是，在多核情况下并非如此。

在全局调度的情况下，优先级调度非常适合。

如果使用优先级继承的调度情况，和前面那个eager的抢占非常相似。

#### 但是迄今为止，没有对于lazy情形下的对于优先级继承的情况的讨论

（这种相似表现出了一种对于优先级翻转的策略的演进）



问题是，在分区情形下，这种情况发生了变化，在前面多核情况下的情形一中，就很典型，因为是分区的，所以优先级并不能查看到另一个核心上面的优先级情况，根本原因是数值的优先级，在不同的系统边界是不可比较的。

这种问题同样出现在分区调度中。



对此的解决方法

名称很多

Allocation继承，SPEPP（spinning processor executes for preempted processors），local helping，多处理器带宽继承，等等。

关键思路是，不仅仅应当继承优先级，也应当继承在某个特定核心上面执行的权利。

也就是说，如果发生了因为共享资源的阻塞，那么应当将持有锁的那个进程迁移到共享资源阻塞的那个核心或者集群上面。

对此的例子是，

低在被高抢占之后，另一个核心上面的中2，发现需要低的资源，所以低被调度到另一个核心上面执行，直到离开临界区，随后中2再继续调度。

从而，大家都满意。以及这种方法，在全局调度或者单核情况下，就演变成普通的优先级调度。



然而，实际情况不是这样，从一个核心迁移到另一个核心其实需要成本，而且有些比如IO端口这种共享资源可能不见得能够进行迁移。

或者另一个远程处理器需要能够完成在临界区的任务的方法——但这种情况可以用一些无锁算法实现。甚至无等待。



## Priority Boosting

接着上面说的那个为关键任务部分添加一个大于任何优先级的优先级来模拟禁止中断的情形。

本来说这样很正常，但是其他任务如果也进入临界区，也会产生优先级提升问题，这又变得可以抢占了（因为两者相同，甚至因为运行时间的问题，后者可能更高）

本质上而言，这是在做一个新的优先级区域

和非抢占一样，都有进度损失问题。



## Restricted Priority Boosting

根本上，上面提出的问题在于，优先级提升不受限制。因此加以一定约束。

例如，priority donation，restricted segment boosting， replica-request priority donation。



## Priority Raising

这是最后一种方案，但是这种方案在于，不是提升到最高，而是有限提升。

期望他会尽快执行占用时间短的临界任务，而具有大的WCET的任务无法抢占

在这篇综述给的例子中，让t1可以依然这样抢占，从而尽快完成t1，但是其他任务也不被延迟特别久。

但这样一来就取决于t1花费的时间长度。

因此并不通常使用。



# 4、自旋锁协议

自旋锁在锁定的时候，并不进行挂起，而是继续自愿的自旋，并且，允许正常的抢占，而且仍然放在就绪队列中去。

首先需要考虑两种不同的blocking

s-blocking，由于自旋造成的延迟

pi-blocking，由于优先级翻转造成的delay。也就是由于低优先级的进程对于共享变量的锁定，所以无法优先访问的blocking。但他此时并不获得锁

我觉得比较大的区别在于，优先级翻转本身是由于作业在调度过程中导致的，所以他还没跑，然后调度器把它延迟了

但是s-blocking，则是由于获取不到共享资源然后自己把自己延迟了，但是这时候他获取到了CPU资源。

必须认真考虑这两种不同的blocking



## 分区调度中的spin-lock协议

MSRP（Multiprocessor Stack Resource Policy）

MSRP是一个对于分区调度的协议，可以用于FP或者EDF

对于全局共享的资源，首先让他变得不可抢占，然后使用自旋锁算法，不断检测，在调度上，则使用一个FIFO的算法，就是把自己挂到一个FIFO队列上去？？？

对于这个算法，配的图，是这样的

234分别运行在三个核心上面，分别试图抢占某个共享资源，使用MSRP，非常不幸的是，2虽然优先级最高，但是由于先来先得问题，2差一点点，所以必须等3和4都用完然后2进入临界区，在2等待的过程中，使用spin lock并且不可抢占，因此，对于同一个核心上面的1来说，虽然1的优先级比2高，但是他必须等待两个阶段，一个阶段是2的s-blocking，这时候，他被spinlock锁定，第二个阶段是，同样由于不可抢占，所以直接pi-blocking。尽管1并不试图获取共享变量。



所以事实上，假设有m个内核spin-lock试图锁定一个共享变量，那么最坏情形下，必须等待所有需要的这m个核心上面都处理好了才能开始处理高优先级，所以如果，核心数很多，那会是一个极限情况下的灾难。



从实现的角度来说，这确实是最简单的方式，没有之一。

有利于操作系统实现。



Gai等提出了一个简单的阻塞分析。先孤立的考虑每个关键部分，然后确定可能引起的最大s-blocking，这个最大s-blocking是包括了其他的核心上面的关键部分长度的总和，然后加上自己的关键部分的WCET（要是不明白就看之前那个1234的例子）

不过作者认为这个做法非常的悲观，关键在于这是单独考虑每个任务的关键部分，所以一个全局的考虑被考虑进来。

Wieder 和 Brandenburg开发了一种基于MILP的阻塞分析。

总而言之推荐看一下这两篇论文的分析方法。

（建议了解）



## Non-FIFO Spin Locks

在某些情况下，并不是FIFO才是最好的，

比如有些情况下需要无序自旋锁，比如TAS指令，用bit位搞事情。如果有些任务要求更高，应当使用优先级自旋锁。

但是相比之下，这种延迟并非简简单单可以分析的，因为优先级可能会导致饥饿，而无序竞争就更不用说了，啥事情都可能搞出来。

Negrean和Ernst [147]以及Wieder和Brandenburg [209]提出了优先顺序自旋锁的适当分析。

并且也分析了无序竞争情况下的情况，这可以被认为，其他核心都认为优先级非常高，而本地核心的任务的优先级最低，这是最坏情况了。

（建议阅读，感觉他们就是搞这个事情的？？？）



## Preemptable Spinning

一个办法是，正如在之前举得例子中，任务1并不试图占用共享资源，因此任务2在s-blocking阶段的时候，完全可以让任务1运行，也就是，允许其抢占。尽管在关键部分的运行的时候依然不允许抢占就是了。

这将最坏的时间从O（m）改到了O（1）

但是问题一在于其实现比较复杂，比如说，当被抢占的时候，必须将自己从那个忙等待的队列中移除出去，或者标记为已经抢占了然后跳过。不能将锁给当前抢占了核心的那个进程（因为确实没卵用，而且说不定不会去解锁）

第二种比较杯具的情形是，被抢占了之后，他一定会退出这个竞争的FIFO队列——否则锁给了他并且让他执行，但是他已经被抢占了，说明他的优先级不高，那肯定违背了高优先级先跑的原则。那退出之后想要锁就必须重新排队，最悲催的事情来了，排队的时候，再次被抢占掉，于是会陷入这种循环直到饿死。



对此的分析工作，Wieder和BrandenBurg进行了P-FP的分析并扩展到P-EDP情况。Alfranseder等人还提出了一个基于FIFO和可抢占的自旋锁协议



## Spin-Lock Protocols based on Priority Boosting

这个办法是Alfranseder提出来的，就是说，在没有发生争用某个共享资源的时候，就正常抢占，但是如果发生了争用资源的情况，则需要提升优先级，其原理是这样的

被称作FEP（Forced Execution Protocol），所谓的按需进行优先级提升。也就是说远程core开始要求共享资源并且开始spin的时候提升优先级。



这种方法，平均而言降低了优先级翻转的时间，但是，最坏情况下的pi-blocking代价很高。

因为在这种情况下，由于优先级的不断提升，从而原本的高优先级的作业有可能会遭受多次pi-blocking

这件事情本身很好理解对吧，对于执行关键任务花费的时间多了，高优先级的任务的时间就少了。

而由于优先级反复提升，所以不断被打断高优先级任务这件事情也很好理解。



FSLM模型flexible spin-lock model

大概是这样的，就是目前要么就是按照MSRP那样子，不允许抢占，要么就是允许高优先级抢占，并且可以做一些提升优先级的事情，这个提升优先级是可以按照任意的中间的优先级来提升的

从而有一种flexible的特点，就是将无条件的优先级提升和FIFO的自旋组成一个灵活的协议，例如之后第五章的FMLP等等。关键是，如果一个自旋着的任务被抢占了，那么他并不需要从该队列中取消作业请求。但是这样依赖，FEP中存在的pi-blocking的最坏情况很高的问题，在这里仍然存在。



（唔我还是继续用那个12345的标号吧，这明显数量不够用了呀）

对此他举得例子是一样的

任务5在核心2上面持有了一个共享资源，然后导致核心1上面的任务234被阻塞了，而核心1上面还跑了原本优先级最高的一个任务1，在FSLM模型中，4被3抢占，3被2抢占，2被1抢占，而且不取消这个核心上面的FIFO队列中的作业请求，这时候5运行完了，由于发生了远程核心争用本地核心的资源的情况，从而需要提升核心1上面的任务234的优先级，而由于不取消作业请求，这时候该核心获取了这个锁，他必须立即先运行相关的作业请求（事实上，抢占1就是用优先级机制来完成的），然后这个顺序就是按照先来后到，从4-3-2，然后任务1就被阻塞很久。



FSLM本身的优先级提升的配置也值得一看（建议阅读）



## Non-Preemptive Critical Sections with Allocation Inheritance

Spinning Processor Executes for Preempted Processors (SPEPP)协议，关键想法在于阻塞作业的处理器应当努力完成阻塞关键部分，而不是在spin中浪费循环



常规情况下是，作业将自己放入自旋队列中，等待，直到持有锁的时候，才执行自己的临界区，而SPEPP协议则是这样的，首先将其打算对共享对象执行的操作和相应的数据（也就是，额闭包closure？？？）放入一个无等待的FIFO队列中去，然后获取实际的锁。然后不仅如此，还执行作业队列中的其他任务，直到他自己的任务被完成。

更重要的是，每个作业被完成之后，他都要检查抢占和中断，因此最大的阻塞变为一个临界区的长度，这也是某种Allocation继承，他试图让作业能够在得到锁的核心上面按照FIFO的原则继续运行。

（虽然这貌似用了所谓奇奇怪怪的闭包这种东西）



一个有意思的地方在于，如果抢占者和被抢占者都试图访问同一个共享资源的时候，上述方案会有一个问题，就是导致长队列的堆积（我个人的理解是，抢占者并没有把自己的任务提前到前面来跑，因此，如果被抢占者有一大堆任务要做就很麻烦，从而实际上访问同一共享变量的时间延长了，导致这个抢占屁用没有，然而我还是不明白为什么）

然后针对于这个访问同一个共享资源的事情，他给了个办法就是说，让抢占者窃取被抢占者的在队列中的槽位，这会导致被抢占者的作业请求被取消掉，因此需要抢占者在结束时恢复被抢占者的任务请求。但是相比于之前提到的可抢占的阻塞，这并不会增加什么s阻塞，因为已经取消掉了被抢占者的槽位。



## Spin-Lock Protocols for Global Scheduling

Holman和Anderson引入了全局调度下的P公平调度下的同步问题，并且引入了短共享资源和长共享资源下的重要区别。

对于短期资源，提出了FIFO自旋锁的协议，

对于长期资源则是在后面讨论，主要是分配继承和信号量算法



Pfair调度算法：比例公平调度



这里只考虑对于短期资源的FIFO自旋锁

PFair是基于量子，因此所有的调度，除了最短的作业，否则都是量子的整数倍



对于关键区跨越量子边界的问题，引入了冻结区的概念





# 5、Semaphore
