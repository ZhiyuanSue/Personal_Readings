写在前面：我这边找到了两个名字很像的文档（当初下载的时候也没仔细辨别），认真看了之后，认为两者应该是同一篇文章的不同时间的更改，在此，采取文章中明确说是2018年末的那一个版本，作为阅读的版本。

大概都是综述类的东西。

我觉得应该先看这个综述，了解各种锁协议

（唔，这124页也内容不少，于是我信心满满的去找网易有道的那个AI去读了，至于效果嘛，这不就是个大号翻译软件？？？不是还是得自己看一遍嘛。。。？而且翻译最多50多页，再往后就加载不出来了，乐）



# Introduction

说，单处理器的实时同步问题已经被充分探索过了，但是在多核上面的情况则并非如此，目前（起码这篇文章弄的时候吧，他说是2018年末）仍然没有一个广泛接受的标准协议或者方法

另一个事情是，忽略了细粒度的嵌套问题（就是在持有一个资源的时候去持有另一个资源），尽管在第九章中实现的（不知道是啥算法）能够支持这个问题。

因此还有很多悬而未决的问题。

关于范围限定，限定在共享内存的多处理器的实时锁定协议上（虽然有些地方可以在分布式系统中应用），并且不考虑替代同步策略（例如无锁定和无等待算法，事务内存技术或者其他的提供事务级别中间件的方法），限制在RTOS并且排除了完全静态的计划方法（就是全都计划好了，从而不需要仲裁）



# 多处理器实时锁的问题（就是存在的问题）

首先定义问题，就是，有共享内存的多处理器，有m个相同的处理器内核组成，管理n个任务，每次激活任务称为作业，这些任务共享一些共享资源，比如共享数据结构，os内部结构，io端口等等等等，通过lock和unlock显式获取和释放。

对于目标，是序列化所有资源请求的lock和unlock包围的代码部分，从而满足所有任务的计时约束。必须考虑由于争用的最大阻塞延迟，从而需要考虑使用哪种类型的锁，必须遵循的规则，以及锁和调度器的交互。

对于一些假定，大多数工作都假定，任务通常周期性或者零星的激活模式（我认为他的意思是，某个任务通常会偶尔的被激活），以及任务的时间要求，通常是确定性的（我对此的理解是，这意味着硬实时，而不是软实时），主要原因是，软实时需要考虑更多。

需要知道每个任务最坏的执行时间（WCET，worst-case execution time），每个关键部分的成本和数量，这个关键部分是不包括阻塞延迟的。



关于处理器调度，分区调度（partitioned）的时候，每个任务会静态的分配给某个处理器，每个处理器使用单处理器策略进行调度，例如fixed-priority（FP）固定优先级调度，或者earliest-deadline first（EDF）调度，所以分区的情况下就是P-FP和P-EDF调度了

在全局调度（global）调度，任务可以在任何处理器上执行，也可以在处理器上面迁移。包括G-FP和G-EDF调度，可选择的包括，P公平调度

第三，还有一种簇调度。m个核分为一系列簇，静态的将任务分配到簇上面去，使用全局调度策略在簇上面调度，假设一个簇中又c个core，global，就相当于m=c，分区调度就相当于m个簇和c=1。会更麻烦一点，虽然这个更通用

所以历史上，作者在考虑锁的时候，通常会集中于global或者partitioned 调度。



一个共享资源如果只被同一个cluster或者core所占用，那么他是local的。否则是全局的。

在分区调度中，可以使用一个已知的最优化的单处理器的协议，例如PCP或者SRP

在簇调度中，可以在每个簇中用一个全局的调度方法



所以在本文中，只考虑global的一个调度算法



## 关键设计选择

- 请求顺序问题，任务必须按照一定顺序进行请求，比如FIFO和优先级队列。也有乱序的，但是，有时候不可避免这个问题。

- 自旋锁和挂起的选择，一般来说，短时间用自旋锁，而挂起则用在长时间。

- 优先级反转问题

- 细粒度锁定问题，可能导致死锁和复杂的阻塞效应，一般来说，两阶段锁定和组锁定

- 就地执行，预先指定一个同步处理器来执行所有的于此相关的临界区

对于其他

需要仔细的分析阻塞的问题，这已经有一些特定和通用的框架



在考虑同步约束的情况下，对于一些系统优化问题，可以形式化

比如给定平台和调度策略和一个锁协议，可以决定好如何将任务映射到处理器上面去

资源映射问题，

平台最优化问题（决定最少需要多少个核心）

策略选择问题



# 历史

没啥大不了的，随便记录

分布式优先级上限协议（DPCP）

多处理器优先级上限协议（MPCP)（建议了解）

多处理器堆栈资源策略（MSRP）（建议了解）

灵活的多处理器锁定协议（FMLP）结合了MSRP和MPCP的许多优点（建议了解），为分区和全局进行了考虑

在这个之后，就有很多论文了



# Progress Mechanisms

反正就是讲一下经典的问题。

先约定好一些规则，使用FP（fixed  priority）固定优先级，按照严格的递减情况（就没有相同优先级的意思），并且使用最简单的挂起锁或者自旋锁，而没有其他的锁协议。

## 单核情况下的优先级反转问题

这个肯定都学过的

分为高中低优先级三个程序

低优先级获取了共享元素的锁，高优先级也想要这个锁，然后低优先级被中优先级抢占了，于是高优先级获取不到这把锁，就超时了。

unbound 优先级反转——因为中优先级的最坏时间（WCET）不确定，所以是unbound

办法有：

优先级继承和优先级天花板协议

优先级继承：

当高优先级请求低优先级的锁的时候，将低优先级的优先级提升到高，等到低优先级离开临界区再降低到原来的情况。

优先级天花板：

当一个进程进入临界区，其优先级就提升到所有可能使用该临界区的最高值。释放临界区之后再回复原来的优先级。



## 多核情况下的优先级反转问题

第一种情况，和单核情况下类似，比如有低和中1，中2，以及高优先级的四个进程在两个核心上面

低获取了锁，中1，中2分别到两个核心上调度并且运行了，那么无论高在哪个核心上面跑，都会被阻塞

更多核心的情况下类似。

第二种情况，同样是低中高三种，低和高在核心1上面，中在核心2上面。

低占用了共享变量，高没有请求共享变量，但是抢占了低，而中在另一个核心上面请求共享变量。

所以从中的角度来说，就被莫名其妙的延迟了。

这主要是在某些分析单处理器的情况下，由于没有考虑到多核对于这个事情的影响，从而造成的问题。

因此，对于优先级翻转这个情况的定义，在多核情况下，不仅仅需要考虑自己单核心的因为抢占和锁问题导致的优先级翻转的情况，还需要考虑多核情况下，在其他核心上通过某种原因导致的本核心上面长时间没有获取共享资源的情况。

对于优先级翻转，在此需要定义为在一个global调度情况下任何会导致m核平台下高优先级的进程等待的情况，都会构成优先级翻转。

全局调度和分区调度的情况都可以这么定义

所以他给了个定义（我不改了直接抄）

```
Def. 1. A job J of task τ i , assigned to a cluster C consisting of c cores, suffers priority-inversion blocking
(pi-blocking) at time t if and only if
1. J is pending (i.e., released and incomplete) at time t,
2. J is not scheduled at time t, and
3. fewer than c equal- or higher-priority jobs of tasks assigned to cluster C are scheduled on processors
belonging to τ i ’s assigned cluster C.
```

这里是用job而不是task。



## Non-Preemptive Sections

最简单的办法是，在持有锁的情况下，拒绝抢占，这样的话，根本不可能被抢占

那么上面多核情况下的第二种情况，在第二个核心上面的中优先级的任务必然会获取到锁，不造成阻塞

不过，这样一来，又造成了高优先级的被低优先级的给翻转了。因为这时候他不允许抢占了。

因此，一个重要的点在于，这不是免费的，必须在等待获取资源的任务和更高优先级之间做出一定的权衡和取舍。



同样的，集群和全局调度的情况下。这种禁止抢占的情形依然是有效的。

但是，这有一定的微妙的地方。

举个例子，在前面的多核情况下的第一种情况中的例子为例，不过现在需要共享数据的进程发生了变化，最低的任务拒绝抢占，然后中1想要这个共享数据，中2并不想，但是在另一个核心上面正常跑，此时，中1会被共享变量所阻塞，但是他可以去抢占在另一个核心上面的中2（尽管抢占了之后仍然会被阻塞）。而中2由于长期获取不到中2跑的这个核心，所以最终会在低跑的核心上面，被高抢占之后，再执行。

所以中1有两个策略，一个是等待低的任务完成，一个是直接抢占另一个核心上的内容（如果另一个核心上的进程优先级更低）

前者被称为lazy preemption（懒惰抢占）或者是link-based global scheduling

后者被称作eager preemption（紧急抢占）



从OS的角度来说，eager是更容易实现的，但是最坏情况下非常糟糕，因为他很有可能反复抢占核心，反复阻塞。

虽然在单核情况下并且没有自动挂起的情况，最多被这样阻塞一次。



而lazy的情况，则是无论如何最多被阻塞一次。

link-based global scheduling，则是在一个基于Linux的实时扩展litmus中被实现。它的名字来源于它在新发布的作业和它应该抢占的非抢占执行作业（如果有的话）之间创建了“链接”;一旦链接的作业退出其非抢占部分，就会立即实施延迟抢占，这可以有效地实现

（我确实觉得这话很绕，我的理解是，一个新的作业，链接了一堆需要他抢占的，但是现在不能抢占掉的作业，如果那些作业的禁止抢占的部分被执行完了，那么就立即执行抢占，他之所以是lazy的，是因为他确实让因为共享条件被阻塞的那些任务，不去抢占别的核心）



对于如何拒绝抢占，在OS中，可以禁用中断，在用户模式中，由于不能禁用中断，所以可以通过为关键任务部分添加一个大于任何优先级的优先级来模拟

但是总而言之有个问题就是，禁用中断对于一些高时间要求的任务容易错过ddl，如果关键部分的任务时间还特别长，那基本gg



## 优先级继承

在单处理器情形下，优先级继承和优先级上限协议已经解决了这个问题，但是，在多核情况下并非如此。

在全局调度的情况下，优先级调度非常适合。

如果使用优先级继承的调度情况，和前面那个eager的抢占非常相似。

#### 但是迄今为止，没有对于lazy情形下的对于优先级继承的情况的讨论

（这种相似表现出了一种对于优先级翻转的策略的演进）



问题是，在分区情形下，这种情况发生了变化，在前面多核情况下的情形一中，就很典型，因为是分区的，所以优先级并不能查看到另一个核心上面的优先级情况，根本原因是数值的优先级，在不同的系统边界是不可比较的。

这种问题同样出现在分区调度中。



对此的解决方法

名称很多

Allocation继承，SPEPP（spinning processor executes for preempted processors），local helping，多处理器带宽继承，等等。

关键思路是，不仅仅应当继承优先级，也应当继承在某个特定核心上面执行的权利。

也就是说，如果发生了因为共享资源的阻塞，那么应当将持有锁的那个进程迁移到共享资源阻塞的那个核心或者集群上面。

对此的例子是，

低在被高抢占之后，另一个核心上面的中2，发现需要低的资源，所以低被调度到另一个核心上面执行，直到离开临界区，随后中2再继续调度。

从而，大家都满意。以及这种方法，在全局调度或者单核情况下，就演变成普通的优先级调度。



然而，实际情况不是这样，从一个核心迁移到另一个核心其实需要成本，而且有些比如IO端口这种共享资源可能不见得能够进行迁移。

或者另一个远程处理器需要能够完成在临界区的任务的方法——但这种情况可以用一些无锁算法实现。甚至无等待。



## Priority Boosting

接着上面说的那个为关键任务部分添加一个大于任何优先级的优先级来模拟禁止中断的情形。

本来说这样很正常，但是其他任务如果也进入临界区，也会产生优先级提升问题，这又变得可以抢占了（因为两者相同，甚至因为运行时间的问题，后者可能更高）

本质上而言，这是在做一个新的优先级区域

和非抢占一样，都有进度损失问题。



## Restricted Priority Boosting

根本上，上面提出的问题在于，优先级提升不受限制。因此加以一定约束。

例如，priority donation，restricted segment boosting， replica-request priority donation。



## Priority Raising

这是最后一种方案，但是这种方案在于，不是提升到最高，而是有限提升。

期望他会尽快执行占用时间短的临界任务，而具有大的WCET的任务无法抢占

在这篇综述给的例子中，让t1可以依然这样抢占，从而尽快完成t1，但是其他任务也不被延迟特别久。

但这样一来就取决于t1花费的时间长度。

因此并不通常使用。



# 自旋锁协议

自旋锁在锁定的时候，并不进行挂起，而是继续自愿的自旋，并且，允许正常的抢占，而且仍然放在就绪队列中去。

首先需要考虑两种不同的blocking

s-blocking，由于自旋造成的延迟

pi-blocking，由于优先级翻转造成的delay。

我觉得比较大的区别在于，优先级翻转本身是由于作业在调度过程中导致的，所以他还没跑，然后调度器把它延迟了

但是s-blocking，则是由于获取不到共享资源然后自己把自己延迟了，但是这时候他获取到了CPU资源。

必须认真考虑这两种不同的blocking




