

来接着有道速读



数据中心运营商今天努力支持微秒级延迟的应用程序，同时尽可能高效地利用有限的CPU资源。为了实现这一目标，一些最近的系统允许多个应用程序在同一台服务器上运行，为每个应用程序提供专用的核心集，并根据负载变化随时间重新分配核心。然而，很多这些系统在处理1微秒这样短的任务时，在延迟和效率之间的权衡上做得不好，牺牲了一个或两个方面的表现。

本文通过模拟比较不同的策略选择，探讨了在**应用程序间分配核心**和在**应用程序内部负载均衡任务**时的最佳组合，发现工作窃取策略在负载均衡中表现最佳，多种策略在核心分配中也能表现良好，而**静态核心分配在小任务重分配中常常优于实时分配**。通过在现有的核心分配系统Caladan上实现最佳策略选择，我们证明这些策略可以提高13-22%的效率，而不会降低（中位数或尾部）延迟。

1 Introduction

现代数据中心应用程序通常涉及许多短的远程过程调用（RPC），这些RPC允许具有大内存占用的应用程序访问其他服务器上的内存，使应用程序能够利用大量的计算资源，提供复制和共识。这些任务的服务时间越来越短，现在通常只有微秒级别。

短任务的服务时间很容易受到延迟膨胀的影响，即使是很小的开销也会使一个1微秒的任务的延迟增加一个数量级。这对于依赖于中位数和分布尾部（例如99%延迟）低延迟的现代应用程序来说是有问题的。因此，研究人员提出了许多技术来减少处理这些短任务的开销。这些系统通过改进低延迟网络堆栈和更好的负载均衡（如DPDK、ZygOS、Shinjuku、eRPC等）或提出新的硬件来更快地将数据包传递给核心（如RPCValet、NeBuLa、NanoPU、Cerebros等）来改进软件。它们使用现有硬件可以实现几十微秒的尾延迟，使用新硬件可以实现几微秒的尾延迟。

随着摩尔定律的放缓，数据中心运营商越来越关注实现高CPU效率。为了实现这一目标，他们将多个应用程序打包在同一台服务器上，以便后台应用程序可以利用由延迟敏感应用程序未使用的任何CPU周期，随着时间的推移，它们的负载会发生变化。最近的一些研究系统通过为**每个应用程序分配一组核心**，然后**在负载变化时重新分配核心**，从而实现了这种部署模型。这些系统通过优化其网络堆栈、线程库和核心分配机制，尽可能地挤出多余的CPU周期和不必要的缓存失效，以在不损害延迟敏感应用程序的延迟或吞吐量的情况下为批处理应用程序提供备用周期。

现有的核心重新分配系统大多关注机制而忽略了实施的策略。每个系统实施两种主要策略：任务负载均衡和核心重新分配。这些策略有很多选择，但每个系统通常只实现一种，缺乏不同策略的比较。常见的负载均衡策略包括工作窃取、工作丢弃和将任务分配到负载较低的核心。核心分配策略可能基于排队延迟、新任务到达或CPU利用率。

本文研究了微秒级任务的负载平衡和核分配策略，发现现有系统为了**保持低延迟**而牺牲了CPU效率，特别是对于短任务。随着任务持续时间从100微秒缩短到1微秒，**平衡任务或重新分配核的开销变得更加显著**，低效的策略变得更加昂贵。本文旨在探讨哪些负载平衡和核分配策略能够在延迟（中位数和尾部）和CPU效率方面取得最佳组合。

PAGE 3

我们关注延迟和效率的结合，因为在理想情况下，我们希望两者都能优化，但它们之间存在固有的权衡。例如，**分配无限核心可以实现最佳延迟，但效率会非常低下**；而分配单个核心可以实现**良好的效率，但可能会导致较高的延迟**。我们所能期望的最好结果是在延迟和效率的帕累托前沿上运行，即在不损害另一个指标的情况下无法改善某一指标。

为了公正独立地比较政策，我们使用模拟来估计任务平衡和核心分配的开销，并模拟常见的负载平衡和核心分配策略。通过因素分析，我们得出了三个关键见解：负载平衡策略和核心分配策略对延迟和效率的影响。

工作窃取是最优的负载平衡策略，可以在保证延迟和CPU效率的同时形成帕累托前沿。这个结论在不同的平均服务时间、服务时间分布、核心数量、延迟指标、核心是否动态重新分配或静态分区以及负载平衡任务的开销等方面都非常稳健。

本文研究了多核处理器上的核分配策略，发现多种策略表现相似，但有些策略表现较差。提前回收核心可以更容易地实现小任务的高效率，特别是在多核心的情况下。本文提出了两种策略，可以在延迟和CPU利用率之间做出不同的权衡，而其他策略则表现较差。

即使采用最佳的核心分配策略，对于小任务来说，通过重新分配核心来实现更好的性能比分配固定数量的核心更困难。对于我们的请求模式（以指数分布的间隔时间建模），在短暂的突发情况下重新分配核心并不能改善延迟（中位数或尾部延迟），相对于静态分配相同平均核心数量。因此，短时间内重新分配核心的主要好处是能够快速适应平均负载的变化。相反，当平均任务服务时间较长（几微秒或更长）时，我们发现即使在恒定的平均负载下重新分配核心也能改善性能。

通过因子分析，研究发现，在没有技术变革的情况下，**工作窃取是最好的负载平衡策略**，基于平均延迟或平均利用率的两种新的核分配策略表现最佳。在实际系统中，将这些策略应用于现有的系统中，可以节省13-22%的核心，而不会降低中位数或尾部延迟。

2 Motivation

为了展示现有系统在处理短任务时的低效率，我们进行了一个实验，在服务器上运行了两个应用程序：一个处理短任务的延迟敏感应用程序和一个消耗所有额外CPU周期的后台应用程序。我们使用memcached作为我们的延迟敏感应用程序，它是一个键值存储，服务时间约为1微秒。我们改变memcached任务的提供速率，并测量每个应用程序完成的有用的应用级工作量。我们使用两个现有系统Arachne和Caladan进行这个实验。

Arachne和Caladan都能提高系统的延迟性能，但它们在为小任务提供低延迟的同时浪费了大量的CPU资源。两个系统在最低和最高负载下的总吞吐量都很高。

Arachne为每个应用程序分配一个核心，因此其后台吞吐量永远不会降至零。

PAGE 4

两个应用程序在高负载下能够以最高效率运行，总归一化吞吐量为1.0。但在中等负载下，两个系统都会出现显著的效率损失，**浪费高达64%或36%的核心**。这种低效率不完全是坏事，多余的周期可以用来更快地处理小任务，降低延迟。

研究表明，系统可以在应用程序之间复用核心，但在处理短任务时效率极低。这引发了一个问题：什么导致了这些效率损失？系统在核心分配策略、负载均衡策略、线程库和使用Linux网络堆栈（Arachne）或内核旁路（Caladan）等方面存在差异。前者的实现方面可能会对效率产生重大影响，但已经得到了先前工作的广泛研究。我们专注于策略方面，并试图了解哪些负载均衡和核心分配策略对小任务的性能产生最佳影响。

3 Design Space of Policies

如果在应用程序之间重新分配核心和在核心之间平衡负载的过程中没有任何开销，那么最优策略是：每当任务到达时立即为应用程序分配一个新核心，并在任务完成时释放核心；将每个新到达的任务引导到其新授予的核心。使用这些策略，CPU使用率将完全匹配任务所花费的时间（100％有效），如果始终有额外的核心可用，则任务将永远不会排队（零添加延迟）。

长任务服务时间较长时，负载均衡和核心重新分配的开销相对较小，因此这些理想化的政策是足够的。然而，对于仅有一微秒的短任务，负载均衡和核心分配的开销变得很大，我们无法为每个到达的任务都执行核心分配和负载均衡操作；这样做会浪费大量的CPU资源。为了获得良好的短任务性能，我们必须考虑其他策略。不同策略之间的关键区别在于它们选择何时产生开销（例如，任务到达时还是队列积累时），而这些选择决定了它们的延迟和CPU效率。因此，找到最佳的负载均衡和核心分配策略就是在负载均衡和核心分配产生开销的情况下，如何最有效地利用这些开销的问题。

3.1 Setting and Assumptions

我们假设每个服务器都运行一个或多个应用程序，每个应用程序可以是批处理应用程序（追求高吞吐量，对延迟不敏感）或处理短任务的延迟敏感应用程序。每个应用程序都被分配了一定数量的核心，当一个应用程序释放一个核心时，如果可能的话，该核心将被分配给另一个应用程序。

本文讨论任务调度问题，任务可以来自外部（例如网络数据包）或本地CPU创建。我们关注使用普通NIC的情况，假设每个核心维护自己的任务队列，任务按**FIFO顺序处理**，没有任务抢占和先验知识。同时，我们讨论了新型NIC硬件的性能变化。

3.2 Policies

本文总结了当前用于负载均衡和核心分配的主要策略，并描述了每种策略产生开销的情况。这些策略是我们在因素分析中评估的策略，旨在覆盖现有策略的主要类别以及理论上的最优策略。

3.2.1 Load-Balancing Policies

负载均衡策略可以在任务到达时或已经排队时进行负载均衡。后者可以根据触发负载均衡的原因进一步划分（核心缺少任务或核心任务过多）。我们首先描述一个理论最优解，然后描述四种实际策略，这些策略可以属于这些类别中的一种或多种。注意，这些策略不一定是互斥的。

单队列负载均衡策略理论上是最理想的，但实际上由于对单一队列的争用而限制了吞吐量。Shinjku和RAMCloud采用了这种方法，但Shinjuku只能支持每秒约500万个请求。

PAGE 5

没有负载均衡。没有负载均衡，任务由它们最初到达的核心处理，例如生成线程的核心或硬件引导数据包或存储完成的核心。这种方法不会产生负载平衡开销。

Enqueue选择策略用于在任务创建时决定将任务分配给哪个核心；任务创建后不能再移动。现有系统通常使用“二选一”策略，将任务排入两个随机选择的核心中负载较轻的那个核心。任务创建时，创建核心需要花费额外开销来对其他核心的队列进行采样（对于少量采样的核心可以并行进行），并将任务排入所选择的核心。

**工作窃取**是一种多线程处理方式，当一个核心空闲时，它会从有任务排队的核心中窃取一半的任务并将其移动到自己的队列中。这种方法被许多系统使用，但会增加检查其他核心的开销。

工作分配。过载的核心可以将负载分配给其他核心或请求其他核心承担部分负载。这种策略可以通过选择一个随机核心并指示其过载来实现。该核心将通过窃取过载核心的一半任务来响应。这是该策略的主要开销来源。

3.2.2 Core-Allocation Policies

核心分配策略的开销主要由重新分配核心所需的延迟和不能有效利用的CPU周期组成。每种策略的性能取决于触发核心重新分配的信号的有效性。大多数策略都会进行核心重新分配。

核心分配决策在固定时间间隔内进行，有些决策是由其他条件触发的。

我们无法轻易地建模或计算出最优的核心分配策略，因为假设有有限数量的核心和非常数的服务时间，找到给定CPU使用限制下的最优尾延迟或反之亦然是NP难问题。我们列出了我们考虑的核心分配策略。

静态核心分配指分配给每个应用程序的核心数量不能随时间变化，这种方法不会产生核心重新分配的开销，但每个应用程序必须分配足够的核心以应对峰值负载，这浪费了大量的CPU资源，这是数据中心工作负载的典型情况。

Fred系统采用每个任务分配一个核心的方式，每次任务到来都会分配一个核心，但这会增加每个任务的核心分配开销，除非所有核心都在使用中。

基于排队的策略根据排队延迟来授予应用程序额外的核心，如果排队（由线程、数据包或存储完成的数量或延迟）超过一定阈值。这些策略根据核心间的最大排队或平均排队来触发。

基于CPU利用率的策略，根据空闲核心数量或核心工作时间占比来添加或撤销核心。

在某些系统中，当核心无法找到任何任务可执行时，应用程序会产生一个核心。这可能发生在核心无法从其他具有排队工作的核心中窃取任务时[26,60,76]，或者在完成当前任务时，使用每个任务的核心分配策略[40]。

3.3 Overheads

本文讨论了负载均衡和核心分配在典型系统中的开销大小。这两种方法都会带来一定的开销。

PAGE 6

**负载均衡开销**受多个因素影响，包括CPU架构、工作负载和预测执行等。尽管如此，我们尝试估计不同负载均衡策略的开销，并证明我们对不同策略相对性能的结论不太可能因为不同的开销而改变。

负载均衡需要核之间的通信，主要由于从另一个核的L2缓存中检索缓存行而导致缓存未命中的开销。根据CPU微架构的不同，这样的缓存未命中的成本可能在30 ns（Intel Haswell）到200 ns（Xeon Phi）之间。负载均衡操作将状态从一个核移动到另一个核，通常需要大约三次缓存未命中来读取远程缓存行，使其无效以便在本地缓存中写入，然后在远程核读取修改后的缓存行时再次发生缓存未命中。执行负载均衡的核所产生的开销大约为两次缓存未命中，即60-400 ns。与此相比，我们测得Caladan平均需要约120 ns来通过工作窃取检查另一个核是否有可窃取的工作（以排队的数据包、线程或定时器的形式）。

单个核心通常可以同时有大约10个缓存未命中。这使得少量独立的缓存未命中可以并行发生。

**核心分配开销**。核心分配完成的延迟取决于重新分配核心的机制。最基本的情况下，重新分配核心需要从做出重新分配决策的核心发送一个处理器间中断（IPI）到将要重新分配给不同应用程序的核心；这需要大约1993个周期或大约1微秒[36]。现有系统报告的核心分配延迟略高，从Shenango中重新分配空闲核心需要2.2微秒，重新分配繁忙核心需要7.4微秒[61]，在Arachne中重新分配核心需要29微秒[67]。

4 Factor Analysis

本节进行因子分析，以确定负载均衡和核心分配策略的相对性能。不能通过比较实现它们的现有系统来有效比较不同策略，因为这些系统除了策略之外还有许多不同之处。

为了研究并行计算中的调度策略，需要进行模拟，因为实际系统的设计可能会受到许多因素的影响，如硬件架构、工作堆栈等。不同的策略可能需要不同的系统设计，例如，系统可能会使用不同的锁机制来保护线程队列，具体取决于策略的要求。因此，为了将策略的行为与实现它们的系统的行为分离开来，需要使用模拟。

我们的模拟依赖于几个参数，这些参数定义了工作负载和对可能的底层系统的假设。我们发现，我们的结论对这些参数的变化非常稳健，因此可能适用于各种实现和工作负载。我们已经在https://github.com/smcclure20/scheduling-policies-sim上提供了我们模拟的源代码。

4.1 Simulation Methodology

本文关注**政策选择**而非实施细节，但我们考虑了跨核心通信和分配核心给应用程序的实际开销。为了公平比较不同政策，我们使用一致的开销值，基于上面测量的开销。我们将负载平衡所需的跨核心通信建模为**100纳秒**。我们将核心分配开销（分配核心的延迟和浪费的CPU周期）**建模为每个核心分配5微秒**。在4.2.1节中，我们将考虑一些不同的负载平衡开销值，但即使将其变化100％，对我们的结果也没有深刻的影响。我们将在4.3节中讨论变化核心分配开销的影响。

我们的模型假设每个核心都有一个本地队列，任务随机到达分配的核心的队列。我们的模拟器模拟了§3.2中概述的各种策略，并根据实际系统实现选择了具体的实现方式。我们承认我们的模型是对这些系统的简化视图，但我们发现在我们评估的系统中，延迟和效率的一般趋势在模拟和实验中是一致的。我们的模拟器不支持抢占，但可以扩展以模拟支持抢占的系统。我们现在描述我们模拟的具体负载平衡和核心分配策略。

本文介绍了三种负载均衡策略：单队列策略、无负载均衡策略和工作分配策略。在工作分配策略中，当一个任务到达时，它会被分配到最短队列中，这个过程需要100纳秒的开销。当工作窃取被启用时，每次检查远程队列都需要100纳秒的开销。当工作分配策略中的工作削减被启用时，每个核心会检查其队列的排队延迟是否高于配置的阈值，如果是，则选择一个随机核心进行通知。远程核心将检查其任务之间的标志，并在两个队列长度平衡时窃取任务，这个过程也需要100纳秒的开销。

PAGE 7

本文介绍了一种基于Fred的任务分配策略，即每当有新任务到达时，立即将其分配到系统中可用的核心上。当任务完成后，如果系统中没有比可用核心更多的排队任务，则该核心会让出资源。

Shenango和Caladan是两种具有相似策略的系统，它们在固定时间间隔内做出决策。模拟会在每个核分配间隔结束时，确定应用程序内核之间的最大排队延迟。如果延迟超过指定的阈值（通常是间隔的长度），则模拟会为该应用程序提供额外的核心。如果核心尝试从应用程序的每个其他核心中偷取任务但未找到任何任务，则应用程序会释放一个核心。在我们的模型中，Shenango和Caladan的主要区别在于它们的间隔/阈值值的差异。

本文介绍了两种新的核心分配策略：**延迟范围和利用率范围**。延迟范围策略通过维护应用程序中所有核心的平均排队延迟来进行核心分配。利用率范围策略则通过维护过去一段时间内的平均CPU利用率来进行核心分配。在每个核心分配间隔（每5微秒）内，模拟会检查平均排队延迟或平均CPU利用率是否超出指定范围，并相应地添加或删除核心。

本文未对核心分配系统的三个重要方面进行建模：一是**一些系统将调度器核心专门用于核心分配决策和启动核心分配**，而另一些系统则通过分布式方式由应用核心执行这些任务；二是未建模**应用程序测量和暴露统计数据时产生的开销**；三是未考虑**核心分配系统的安全性和可靠性**。

该段文字提到了三个限制：首先，该方法只适用于单个应用程序的多个实例，而不是多个不同应用程序之间的共享资源；其次，该方法需要应用程序核心将少量状态（例如，任务排队时的时间戳）写入共享内存；第三，该方法没有考虑将核心从一个应用程序重新分配到另一个应用程序时的缓存影响。

每个政策都有独特的参数，我们使用表2中默认的参数值，这些值是基于每个政策的最佳表现而选择的。虽然我们将在本节中讨论可配置性的影响，但除非另有说明，否则我们将使用这些特定的值。

我们的模拟中使用了32个核心的规范配置，服务时间呈指数分布，平均为1微秒，到达时间呈泊松分布，平均负载占据平均核心数的50%。实验将独立地改变这些维度，但默认情况下我们将使用这个配置。为了说明上述策略开销的背景，平均任务时间设定为1微秒，负载均衡的开销为平均任务时间的10%，而核心重新分配的开销为500%。

4.2 Load Balancing

首先，我们评估了在静态分配核心的情况下不同的负载均衡策略对性能的影响。然后，我们评估了核心重新分配是否会影响这些发现。

4.2.1 With Static Core Allocations

首先，我们独立评估每个负载均衡策略，不考虑任何特定的核分配策略，通过使用固定数量的核心来运行每个实验。这样可以确定在给定相同总CPU周期的情况下，每种方法的相对性能，因为给定的分配策略会根据特定负载均衡方案的行为做出不同的分配决策，即使在相同的流量下也是如此。通过解耦两者，我们可以确定哪些端到端效果是特定于负载均衡策略的。

图3展示了不同负载均衡策略的尾延迟和中位数延迟随着静态分配核心数量的变化情况。每条曲线对应一个负载均衡策略，平均负载为50%，曲线上的点表示延迟，x轴表示静态分配核心数量。一般来说，图中左下角的策略更优。其中JBSQ曲线将在后面讨论。

PAGE 8

静态核心分配中，工作窃取比工作丢弃或入队选择在给定效率（分配核心数）下具有更好的延迟（中位数和尾部）。

工作窃取策略相对于其他负载均衡策略具有更低的中位数和尾部延迟，是最优的选择。相对于入队选择和工作丢弃，工作窃取具有更好的性能。入队选择和工作丢弃的相对性能取决于系统和工作负载参数，如分配的核心数、延迟百分位数和服务时间分布。

本文研究了任务调度算法中的两种方法：工作窃取和入队选择。结果表明，工作窃取比入队选择更优秀，因为入队选择存在三个主要限制：任务负载平衡开销、有限的队列选择和基于排队任务数量而非服务时间总和的放置。这些限制可能导致负载不平衡和空闲核心无法帮助“滞留”任务。通过选择队列中服务时间总和或增加队列选择数量可以改善尾延迟，但这些方法并不总是实用的。将开销降至0提供了比这些方法更大的性能优势。

工作窃取和工作丢弃之间的尾延迟差异可以通过将最终处理它的核心移动到贡献尾延迟的任务所需的步骤来解释。在工作丢弃中，对于超载核心上的任务，需要等待跨越信号阈值，等待核心完成当前任务并提高标志，以及等待远程核心响应。在工作窃取中，任务只需等待工作窃取核心检查它们的队列；这种延迟主要取决于多余核心的数量。在工作丢弃的队列阈值为2微秒的情况下，我们发现被丢弃的任务平均花费3.1-4.5微秒在最终处理任务的核心以外的核心上排队，而使用工作窃取时为0.3-1.4微秒。大多数尾延迟的任务至少被窃取一次，解释了两者之间尾延迟的差距。降低队列阈值只会带来微小的改进，因为在更高的负载下，大多数核心将始终有一个待处理的标志。此外，没有抢占，任务仍然会因为上述两个步骤而产生延迟。

本文研究了不同负载均衡方法的性能，发现工作窃取方法在大多数情况下表现最佳。即使负载均衡开销为400纳秒，工作窃取方法仍然表现最佳。此外，本文还探讨了硬件变化对结果的影响，发现工作窃取方法仍然是最优解。

工作窃取算法在不同延迟百分位数、平均服务时间、核心数、负载和服务时间分布下都表现出优异的性能。在服务时间分布为常数时，负载平衡策略的具体选择对系统性能的影响较小。在所有评估的服务时间分布中，静态曲线的排序顺序与指数分布相同。

PAGE 9

这段文字讨论了将不同的负载均衡策略结合起来使用的可能性。这些策略可以在任务处理的不同阶段发挥作用，从而实现更好的负载均衡效果。作者通过模拟静态核分配的情况，将工作窃取策略与其他策略相结合。

静态核心分配下，加入工作丢弃可以提高尾部延迟，但加入工作窃取的入队选择会使性能变差或不变。

在使用工作窃取的系统中添加任务入队选择不会提高性能，因为在少量核心的情况下，每个任务的开销会降低吞吐量，而在许多核心的情况下，工作窃取和单队列之间的改进空间很小。但是，在工作窃取中添加工作丢弃机制可以在高负载条件下帮助平衡队列，尽管效益在某些效率下受到限制，因为标记的开销可能会变得过高。

本文提出两个问题：（1）**如果网卡可以进行更智能的分配，而不是简单的哈希分配，会有什么影响？**（2）同时处理多个缓存未命中会有什么影响？其中（1）是受到最近提出的系统NanoPU的启发，该系统根据加入有限最短队列（JBSQ）为传入的数据包选择队列，可以实现良好的性能提升。但是，这需要新的硬件来智能地指导传入的流量。

为了解决第二个问题，我们模拟了一些情景，其中底层硬件可以同时解决多个缓存未命中（如第3.3节所述）。最终，这种能力意味着负载均衡策略可以与多个核心进行通信，只需付出一个核心的代价（例如，在工作窃取中检查10个核心是否有可用工作）。然而，我们发现这些修改的效果有限。

并行检查虽然可以提高系统的效率，但是在实际应用中，其效益很有限，甚至可能会增加额外的开销。

工作窃取是最好的负载平衡策略，即使负载参数和开销变化，也能保持高性能。它通过避免每个任务的开销和利用空闲核心来避免任务在超载核心中滞留，从而实现高性能。在没有新硬件的情况下，工作窃取是我们评估的负载平衡策略中最好的选择。我们相信，我们是第一个将其与其他策略进行比较并展示其处理微秒级任务时的优势的人。

4.2.2 With Dynamic Core Allocations

本文研究了当核心可以重新分配时，负载平衡策略的表现。当分配给应用程序的核心数量随时间变化时，很难比较不同策略的效果。有些核心分配策略是可配置的，可以调整以比较它们的延迟，但并非所有策略都可以调整。因此，不能总是说一个策略组合比另一个更好。

本文介绍了在Shenango/Caladan中，如何将核心分配策略与负载均衡策略相配对，并对一些配对进行了修改或调整。同时，对于任务分配，只有在工作保持负载均衡策略下才能保证活动核心数等于任务数和总核心数的最小值。

本文模拟了负载均衡和核心分配策略的所有相互一致的组合，以比较它们如何探索可用的权衡空间。结果显示在图5中。

研究发现，当核心动态重新分配时，工作窃取比丢弃或入队选择表现更好，并且对于研究中提到的所有因素都具有鲁棒性。

图5a展示了静态分配曲线和负载均衡和核心分配策略的每种组合。比较每种核心分配策略在不同负载均衡策略下的表现，我们发现工作窃取策略总是最接近单队列曲线。注意，该图仅显示每种核心分配策略的一个参数选择，但有些可以配置以进行不同的延迟与效率权衡。我们通常选择最接近图表左下角的配置，但我们将在第4.3节中广泛讨论可配置性。

PAGE 10

动态核心分配虽然使得每个负载均衡策略的个体表现不太清晰，但总体而言，工作窃取仍然比其他负载均衡方法表现更好（在没有新硬件的情况下）。

4.3 Core Allocation

本文比较了不同的核心分配策略的性能，这些策略旨在对负载变化做出反应，其性能往往与负载平衡策略密切相关。

更好的负载均衡策略能更有效地利用可用的计算周期，从而使核心分配策略在授予核心时更加保守。因此，我们评估每个负载均衡策略下的每个核心分配策略，并寻找每个核心分配策略在效率和延迟之间的权衡模式。

一些现有系统使用额外的专用核心来执行核心分配，但本文关注的是策略而非实现，因此不计算这些核心。如果计入这些核心，32核系统的所有效率结果都将增加3%的CPU利用率。

本文探讨了是否将核心重新分配能够比保持核心数量不变获得更好的性能。然而，令人惊讶的是，我们发现答案通常是否定的。即使平均负载保持不变，能够对负载突发性做出反应也不一定会带来显著的性能优势。

**短任务方面，核心分配策略无法比静态核心分配策略更好地实现给定平均效率下的延迟**（中位数或尾部）。但是，对于长任务，这是可能的。

在图5a中，没有任何核心分配策略能够在相同效率下实现更好的尾延迟（点位于相应静态核心分配曲线的上方和右侧）。当平均任务服务时间较长时（例如10微秒或100微秒），一些策略组合可以比静态分配曲线实现更好的性能。随着平均任务持续时间的增加，核心分配开销的相对重要性降低，为额外任务分配新核心变得相对高效。唯一能够击败相应曲线的策略组合是以工作窃取为负载平衡策略的组合。

PAGE 11

为了超越静态曲线，需要反应极快的核心分配系统，比5微秒更频繁地做出分配决策，并在不到5微秒的时间内将新核心分配给应用程序。然而，频繁的分配会带来状态检查和核心重新分配的开销，这在实际实现中是具有挑战性的。在Shenango中，这些操作需要大约2.1微秒或3.4微秒，具体取决于应用程序核心的数量。完成每个核心重新分配也同样具有挑战性。

为了适应负载变化，可以采用核心分配策略，而不是为恒定负载分配静态核心数量。反应速度慢也不会表现良好。平均负载在数据中心中会随时间变化。静态分配核心会浪费CPU周期，而反应速度慢会导致显著的尾延迟峰值。

本文评估了不同的核分配策略在性能一致性和高CPU效率方面的表现，并发现了表现一致的策略。一些核分配策略在工作负载和负载方面相对于静态曲线的位置可能会有很大的变化，使得操作员难以配置策略以实现他们的目标。通过比较核分配策略在工作负载和负载方面的权衡，我们找到了表现一致的策略。

优化用户可见指标的政策在不同配置下表现更加一致。

图5展示了在不同服务时间下，Caladan和pertask的操作点会发生变化。而利用率范围和延迟范围则规定了系统不应该离开的x和y轴的范围，这通常会强制点落在静态分配曲线的特定区域内。例如，在图5中，利用率范围点在所有服务时间下都能实现接近60%的CPU利用率。

本文研究了不同的核心分配策略在不同负载下的性能表现。实验结果表明，延迟范围和利用率范围等策略在不同负载下的性能表现更加稳定，可以直接调整策略参数以达到特定的性能目标。相比之下，Caladan、Shenango和per-task等策略在不同负载下的效率和尾延迟表现不一致。

我们考虑每个核心分配策略是否可以配置在靠近每个静态分配曲线的拐点处运行，以实现高CPU效率，同时最小程度地影响尾延迟。

当没有排队的工作或工作窃取失败时，只有在找不到工作时才会释放核心，这使得在处理小任务时尤其是在使用多个核心时很难实现高效率。

本文分析了不同的核心分配策略在与工作窃取相结合时的表现。结果显示，当核心数量较多时，只有延迟范围和利用率范围两种策略能够实现较好的CPU效率。此外，利用率范围和延迟范围还能在保持相似尾延迟的情况下节省多达15个核心。

PAGE 12

Shenango、Caladan和per-task策略的效率受限，因为它们分配核心的速度较慢。这些策略的效率受限于分配核心的开销，因为在分配所有核心之前，效率无法超过T/(T+R)，其中T是平均任务时间，R是核心分配开销。因此，为了实现高效率，必须采用主动撤销核心的策略。

研究了维护一定数量的空闲核心的策略，但在短的核心分配间隔下噪音太大，表现明显不如其他策略。

静态核心分配适用于小任务且平均负载已知，但动态分配策略在负载未知或变化时表现更好。主动撤销核心的动态分配策略最佳。

4.4 Policy Takeaways

本文研究了在没有新硬件的情况下，如何实现负载均衡。研究发现，最好的方法是使用工作窃取策略，并根据端到端指标的重要性选择延迟范围或利用率范围来进行核分配。这两种策略都能够在短任务中接近工作窃取静态曲线，或在长任务中优于曲线。这两种策略都很稳健，能够应对服务时间变异、不同的服务时间分布、负载变化和核数变化。最后，这两种策略都是可配置的，允许操作员选择CPU效率或尾延迟（以及程度）。这些方法很直观，因为核分配策略在CPU效率和尾延迟之间做出了权衡，因此有效地使用这两个参数作为重新分配核心和控制权衡空间的信号是有意义的。

5 Implementation

我们通过扩展Caladan来在真实系统中实施我们的政策。Caladan的关键组件是应用程序运行时和专用调度器核心，它实现了核心分配策略。Caladan提供轻量级用户级线程、高性能网络堆栈和通过工作窃取实现的负载均衡。与Shenango相比，它还能提供更高的网络吞吐量，并且其核心分配机制更具可扩展性。

该文介绍了在Caladan上实现延迟范围和利用率范围的方法，需要对运行时和调度器进行小的修改。运行时已经提供了有关线程和数据包排队延迟的信息，我们增加了有关CPU利用率的信息，并添加了应用程序核心在调度器核心通知时自愿让出的能力。调度器核心会轮询应用程序公开的利用率信息，并根据当前策略使用此信息或延迟信息来决定是否添加或撤销核心。当需要撤销核心时，调度器会撤销当前排队工作最少的核心。

在实践中，测量应用程序核心的CPU利用率比模拟更具挑战性。这是因为我们不会中断正在运行的任务来记录CPU使用情况，只有在任务开始或结束时才记录CPU时间的使用情况。因此，如果一个任务在5微秒的核心分配间隔的整个时间内运行，调度器核心将观察到应用程序和运行时调度器在该核心上都没有花费任何周期。调度器核心通过假设当应用程序核心在核心分配间隔内报告没有CPU使用时，它们的利用率为100％，并添加一个核心来处理这种情况。如果应用程序没有分配CPU核心，则CPU利用率不是决定应用程序是否需要更多核心的有用指标。因此，无论核心分配策略如何，调度器核心始终使用数据包的到达来决定何时授予应用程序其第一个核心，就像Shenango和Caladan一样。

6 Evaluation

本文旨在验证高性能策略是否能在实际系统中提高性能。由于在单个系统中变化负载平衡策略需要进行重大系统更改，因此我们将重点评估核心分配策略。我们评估了四种策略：Shenango、Caladan、延迟范围和利用率范围。我们使用最佳性能的负载平衡策略（工作窃取）的系统（Caladan）进行评估。

PAGE 13

实验设置：使用两台双插槽服务器进行实验，配备28核Intel Xeon Platinum 8176 CPU，主频为2.1 GHz。服务器配备40 Gbits/s Mellanox Connect X-5 Bluefield NIC（不使用SmartNIC功能），客户端配备Intel E810C 100 Gbits/s NIC。启用超线程，禁用TurboBoost和频率缩放。在第二个插槽上使用32个超线程（连接了NIC）。使用Ubuntu 20.04操作系统，内核版本为5.4.0。

本文使用memcached作为应用程序，使用Caladan的负载生成器loadgen生成请求，根据Facebook的USR请求分布生成读写请求混合的工作负载，同时运行PARSEC基准套件中的swaptions工作负载作为后台应用程序。评估不同策略的性能。

6.1 Policy Comparisons

实验结果表明，不同的策略会产生不同的延迟与CPU效率权衡，但延迟范围和利用率范围通常优于Shenango和Caladan，证实了我们基于模拟的因素分析的发现。图8a显示了memcached的尾延迟，图8b显示了后台应用程序实现的吞吐量，两者都是在我们变化memcached提供的负载时（x轴）展示的。我们展示了两种不同的延迟范围配置，以说明调整目标范围的影响。

新的调度策略（延迟范围和利用率范围）在memcached的尾延迟方面与Caladan和Shenango相似，同时实现了更高的CPU效率。与Shenango和Caladan相比，这两个新策略为后台应用程序提供了多达22%的总吞吐量（7个超线程），比Caladan多13%（4个超线程）。这是因为Shenango和Caladan的策略使memcached在运行时调度器中花费更多的时间，而这两个新策略则通过主动撤销未使用的核心来实现更高的CPU效率。

延迟范围和利用率范围策略都需要输入目标范围，可以通过调整范围来在尾延迟和CPU效率之间做出不同的权衡。例如，延迟范围1-4微秒比延迟范围0.5-1微秒可以为批处理应用程序提供约2个超线程的额外吞吐量，但代价是10-15微秒的尾延迟。

7 Related Work

负载均衡策略是研究过的，有些系统采用单一共享队列，但会出现吞吐量瓶颈，有些则不在软件中进行负载均衡，而是由NIC或存储设备随机分配工作，但会出现负载不平衡的问题。

工作窃取是一种有效的多线程计算调度方法，已被广泛应用于各种平台和系统中。其中，基于2的幂次选择负载平衡策略被广泛研究和采用。最近，一些系统开始采用更先进的负载平衡策略，如JBSQ。这些策略的应用可以提高系统的效率和性能。

PAGE 14

本研究发现，与以往的负载均衡策略比较一致，"先工作"的负载均衡策略（如工作窃取）具有更好的性能。但是，本研究有两个关键的不同之处：首先，我们不知道有任何先前的工作在考虑实际的负载均衡开销时比较负载均衡策略；其次，以往的工作评估的指标是延迟、吞吐量和通信速率，但没有考虑CPU效率。相比之下，本研究比较了不同策略在负载均衡开销存在的情况下在延迟和效率方面的权衡。

现有系统采用不同的策略来决定何时重新分配核心，这些策略基于任务到达、排队延迟、CPU利用率或找不到工作等因素。过去的研究指出，工作窃取核心可能浪费大量CPU周期，并提出了让出核心的策略来缓解这种情况。然而，这些策略针对的是长时间任务的吞吐量和公平性，而我们的分析则关注微秒级任务的效率和延迟，因此得出了不同的结论。

Syrup和ghOSt系统可以让用户通过编写用户空间代码来控制内核调度程序、网络堆栈和网络卡的调度策略，但它们并没有指定用户应该实现哪些策略。这些系统与本文的工作相互补充。

8 Conclusion

本文系统评估了不同策略对效率和延迟的影响，以确定在考虑实际开销时，哪些负载平衡和核分配方案能够实现最佳性能。工作窃取是当今硬件中最好的策略选择，而核分配空间更为复杂。本文设计和实现了两种核分配策略，它们与工作窃取配对时能够提供一致和可配置的性能，并展示了它们如何在不牺牲延迟的情况下提高效率。

9 Acknowledgments

感谢Ana Klimovic牧羊人、匿名审稿人、John Ousterhout和NetSys成员的有用反馈。感谢Daniel Grier协助完成NP难度证明。本研究部分资金来自NSF Grants 1817116和1704941，以及Intel、VMware、Ericsson、Futurewei和Cisco的资助。

References

A Appendix

PAGE 18

A.1 Proof of NP-Hardness for Optimal Core Allocations

本附录证明了在给定CPU使用率限制或反之亦然的情况下，找到最优的尾延迟是NP难问题，假设核心数量有限且服务时间不是常数。我们使用多处理器调度决策问题的归约来证明这一点。

Multiprocessor Scheduling Problem [28]

输入：核心数量c，任务集T，每个任务t的服务时间l(t)，以及完成所有任务的总截止时间D。

问题：是否存在一个任务T在c个核心上的时间表，满足总体截止时间D？这样的时间表为每个任务分配一个开始时间，使得同时处理的任务数不超过c，并且对于每个任务，其开始时间加上l(t)不超过D。

多处理器调度问题是NP完全问题，假设所有任务的服务时间不相同；如果服务时间是恒定的，则该问题是微不足道的。

Optimal Core-Allocation Problem

输入：核心数量、任务集合、启动时间、浪费CPU时间、尾延迟百分位和目标。

是否存在一种计划，使得任务只在开启的核心上调度，浪费的CPU时间最多为W，百分位数为P的延迟最多为L？核心的计划为每个核心分配开启和关闭时间段，从关闭到开启需要S时间。任务的计划为为每个任务t分配一个开始时间，使得t的开始时间至少为a(t)，同时处理的任务数不超过开启的核心数。最后，对于P％的任务，它们的开始时间加上l(t)不超过L。

将多处理器调度问题转化为最优核心分配问题。核心分配问题中的核心数量与多处理器调度问题中的数量相匹配，将L和D设置为相等。通过复制多处理器调度问题中的任务和服务时间，构建核心分配问题的任务集，并将它们设置为同时到达（即对于所有t∈T，a(t) = 0）。此外，添加额外的虚拟任务，使得多处理器调度问题中的任务占总任务数的百分比为P；由于虚拟任务不可能满足延迟限制，只有非虚拟任务才能满足延迟限制。最后，将启动时间S设置为零，浪费的CPU时间限制W设置为足够高以忽略（例如，W ≥ c·D）。可以简单地证明，如果对应的多处理器调度问题存在多项式时间算法，则存在一个多项式时间算法来解决这种最优核心分配问题的实例。此外，最优核心分配问题显然属于NP类问题；因此它是NP完全的。

PAGE 19

由于最优核心分配决策问题是NP完全问题，因此找到给定效率限制下的最优尾延迟或反之亦然的优化问题是NP难问题。这个证明假设服务时间分布l(t)不是常数；具有常数服务时间的优化问题也可能是NP难问题，但无法使用上述证明来证明。

A.2 Extended Factor Analysis

本附录包含因子分析中为节省空间而省略的额外数据。

A.2.1 Additional Loads for Static Curves

图5比较了不同负载均衡策略在不同平均服务时间下的性能，证明短任务更难超越静态分配。图9变化了负载，观察效率和延迟。要查看负载下的完整效率和延迟，请参见图7。

A.2.2 Additional Service Time Distributions

我们比较了不同服务时间分布下的负载均衡策略。具体来说，我们为每种负载均衡策略创建了静态分配性能曲线，其中包括常数服务时间为1微秒和双峰分布，其中90%的请求的服务时间为500纳秒，剩下的10%的请求的服务时间为5.5微秒（平均服务时间为1微秒）。在图10中，我们可以看到在这些不同的服务时间分布下，工作窃取策略始终优于其他负载均衡策略。当服务时间恒定时，负载均衡选择对端到端性能的影响较小（图10a），因此工作窃取策略提供的好处较小。
