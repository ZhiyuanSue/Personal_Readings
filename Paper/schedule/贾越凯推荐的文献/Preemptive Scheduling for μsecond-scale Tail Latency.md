这篇文章介绍了由斯坦福大学和麻省理工学院的研究人员共同开发的一种新型计算机网络协议，该协议可以提高网络的安全性和可靠性。

该研究由斯坦福大学的David Mazières和Christos Kozyrakis进行，旨在探讨分布式系统的安全性和可扩展性。

这篇论文被收录在NSDI19会议的论文集中。

本文介绍了第16届USENIX网络系统研讨会。

本文介绍了NSDI '19会议上的一篇关于设计和实现的论文。

2019年2月26日至28日，美国马萨诸塞州波士顿举办了一场活动，ISBN号为978-1-931971-49-2。

Shinjuku: Preemptive Scheduling for µ second-scale Tail Latency

PAGE 2

David Mazi`eres和Jack Tigar Humphries是两个人的名字。

Christos Kozyrakis是斯坦福大学和麻省理工学院的教授。

Abstract

IX和ZygOS等微秒级应用的最新提议的数据平面使用非抢占策略来调度核心的请求。对于许多实际场景中请求服务时间呈高离散度或重尾分布的情况，它们允许短请求被长请求阻塞，导致尾延迟较差。

Shinjuku是一个单地址空间操作系统，利用硬件支持的虚拟化实现微秒级的抢占，可以实现集中式调度策略，适用于轻重尾请求服务时间分布。在各种工作负载场景下，Shinjuku相比IX和ZygOS提供了显著的尾延迟和吞吐量改进。在处理点查询和范围查询的RocksDB服务器的情况下，Shinjuku的吞吐量高达6.6倍，尾延迟降低了88%。

1 Introduction

云应用的响应时间受到最慢的机器的影响，需要每个服务的尾延迟在微秒级别。然而，现代操作系统的线程管理不适合微秒级任务，会产生毫秒级的尾延迟。

研究人员开发了绕过操作系统的网络堆栈、数据平面和完整应用程序，以弥补操作系统网络性能不足的问题。这些系统使用接收端扩展（RSS）来分配请求，使用分布式排队和先进先出（FCFS）调度来处理请求，采用优化措施来降低开销。这些系统的调度方式被称为分布式排队和FCFS调度，或d-FCFS。

d-FCFS适用于请求服务时间分布较小的情况，如Memcached等简单内存键值存储。但在高分散或重尾请求分布下表现不佳，也不具备工作保持能力。RSS的流一致哈希实现的d-FCFS只有在客户端连接数量很高时才能近似真正的d-FCFS。

ZygOS [46]通过实现低开销的任务窃取改进了d-FCFS，即完成短请求的线程从被长请求占用的线程中窃取工作。它近似于集中式FCFS调度（c-FCFS），其中所有线程都服务于一个队列。任务窃取并不是免费的。它需要扫描缓存在非本地核心上的队列，并将系统调用转发回请求的主核心。然而，如果服务时间具有低离散度，并且有足够的客户连接使请求均匀分布在队列中，窃取发生的频率很低。

c-FCFS对于遵循重尾分布或具有高离散度的请求时间的工作负载也是低效的。这些工作负载包括根据搜索词的流行度对一定数量的项目进行评分和排序的搜索引擎；微服务和函数即服务（FaaS）框架；以及支持简单的获取/放置请求和复杂的范围或SQL查询，并且除了快速DRAM之外还使用较慢的非易失性内存的内存存储或数据库。理论告诉我们，这些工作负载在尾延迟方面在处理器共享（PS）下表现最好，其中所有请求都获得可用处理能力的细粒度、公平的一部分。

PAGE 3

为了近似PS，我们需要使用抢占式调度，这是现代内核调度器（包括Linux）的一部分。然而，任何使用每个请求或连接一个线程并允许Linux管理线程的服务都会遇到毫秒级尾延迟，因为内核以毫秒级粒度进行抢占，并且其策略未经过优化以实现微秒级尾延迟。用户级协作线程库可以避免内核调度的开销。然而，对于处理时间较长且没有太多阻塞I/O调用的请求，很难在请求期间频繁让出CPU，而这些请求恰恰会影响尾延迟。

Shinjuku是一个单地址空间操作系统，实现了微秒级的抢占式调度，提高了轻重尾服务时间分布的尾延迟和吞吐量。它通过一个或多个专用的调度线程实现真正的集中式调度，而不是强调RSS。它利用虚拟化的硬件支持（特别是发布的中断）来实现调度器核心的298个周期和工作核心的1212个周期的抢占开销。单地址空间架构使我们能够将上下文切换优化到110个周期。

Shinjuku系统支持微秒级尾延迟，可以在5微秒内切换请求，开发了两种调度策略，第一种根据观察到的服务时间选择FCFS或PS，第二种可以将不同服务级别的请求分离以确保短请求和长请求的尾延迟都很好。这两种策略适用于多种服务时间分布，使Shinjuku成为第一个支持超过固定或低分散服务时间分布的工作负载的微秒级尾延迟的系统。

本文介绍了一种名为Shinjuku的新型数据平面操作系统，与IX和ZygOS进行了比较。使用合成工作负载，证明Shinjuku在轻尾工作负载方面与IX和ZygOS的性能相当，而在重尾和多峰分布方面支持高达5倍的负载。使用支持范围查询的流行键值存储RocksDB，证明Shinjuku在给定99th百分位延迟下的吞吐量方面比ZygOS提高了多达6.6倍。同时，Shinjuku能够很好地扩展到可用的核心数量，能够饱和高速网络连接，并且即使连接数很少也很高效。

本文介绍了Shinjuku的设计和实现，该系统旨在实现微秒级的抢占式调度。文章首先阐述了微秒级抢占式调度的必要性，然后详细讨论了Shinjuku的设计和实现。接着，文章进行了全面的定量评估，并讨论了相关工作。

Shinjuku是开源软件，代码可在GitHub上获取。

2 Motivation

本文旨在提高单个服务器上延迟关键服务的SLO。对于云服务和高扇出的微服务，Shinjuku必须在微秒级别上实现低尾延迟。低平均或中位延迟是不够的。为了经济实惠，Shinjuku必须在高请求吞吐量的情况下保持低尾延迟。最后，它必须适用于各种工作负载，并支持简化大型代码库的开发和维护的直观API。

实现低尾延迟和高吞吐量的关键是有效的请求调度，需要在微秒级别上运行的低开销机制和良好的策略。良好的策略在单独情况下很容易实现。不幸的是，由于抢占和上下文切换开销以及同时适应不同时间尺度上的批处理、后台和交互任务的复杂性，Linux内核调度器在毫秒级别上运行。

最近的用户级网络堆栈、数据平面、RPC协议和应用程序提议，旨在优化尾延迟和吞吐量，避免庞大的内核网络和线程管理堆栈。这些系统大多使用RSS来近似d-FCFS调度策略，其中IX数据平面是一个典型的例子。ZygOS通过使用工作窃取来近似c-FCFS，改进了IX。使用libevent或libuv构建的Linux应用程序也实现了c-FCFS，但由于使用中断进行请求分发而不是RSS和轮询，开销更高。

PAGE 4

为了比较不同调度策略的差异，研究人员开发了一个离散事件模拟器，并使用该模拟器比较了不同调度策略的性能。在简单的工作负载下，d-FCFS是可接受的，但在中等和高负载下会出现问题。c-FCFS是最优的，而PS略差一些，因为它会抢占短请求。模拟器允许配置参数，如调度策略、主机核心数、系统负载、服务和到达时间分布以及各种系统相关开销。

d-FCFS不适合处理重尾请求分布，如搜索引擎或垃圾回收等活动所引起的分布。c-FCFS表现更好，因为工作人员可以处理任何请求，只有在大多数工人同时处理较旧的长请求时，短请求才会被延迟。

在轻尾双峰分布下，FCFS表现明显较差，而PS通过抢占长请求来交替执行短请求，能够很好地处理重尾和轻尾的情况。

PAGE 5

图2展示了在一个双峰负载下，短请求和长请求的性能表现，其中服务时间均匀分布在1微秒和100微秒之间。这近似于一个KVS，其中一半的请求是get/put请求，另一半是范围查询。图(a)和(b)分别绘制了两种请求类型的尾延迟，图(c)显示了所有请求的请求减速度的99th百分位数，这是一个有用的指标，用于衡量我们实现减少所有请求类型排队时间的目标的效果。

d-FCFS和c-FCFS都会惩罚1微秒的请求，c-FCFS对于100微秒的请求略优于PS，但对于短请求的惩罚远大于对长请求的好处。

新宿方法旨在实现低开销的抢占和上下文切换机制，以适用于微秒级工作负载的所有可能的服务时间分布。这些机制可以实现最佳的PS和c-FCFS策略，而其他系统无法实现类似的策略是因为这些策略需要在任意执行点进行抢占，而抢占通常涉及中断和内核线程，其开销与微秒级延迟不兼容。

3 Shinjuku

Shinjuku 1是一种适用于低延迟应用的单地址空间操作系统，采用集中式排队和调度架构，依靠低开销和频繁抢占来确保各种服务时间分布的低尾延迟。与IX和ZygOS不同，Shinjuku不依赖于RSS来分配请求，而是采用中心化的排队和调度架构。

3.1 Design Overview

Shinjuku的关键组件包括网络子系统、调度器和工作线程。网络子系统处理所有网络协议处理和识别请求边界，可以使用专用核心、智能网卡或两者的组合实现。调度器将请求排队并分配给工作线程，每个请求都有一个上下文以支持抢占和重新调度。工作线程使用专用硬件核心或超线程执行请求，大多数请求将在不中断的情况下完成执行。工作线程通知网络子系统释放为传入请求分配的任何缓冲区空间。

Shinjuku操作系统的调度程序使用时间戳来识别长时间运行的请求，并根据调度策略进行抢占。对于我们研究的工作负载，假设有排队的请求，我们会在5微秒到15微秒后抢占正在运行的请求。Shinjuku是一个单地址空间操作系统，其组件之间的通信通过共享内存进行。我们为每对通信线程使用专用的缓存行。

ing steps · - » as many times as needed.

PAGE 6

Shinjuku使用Dune系统进行进程虚拟化，类似于IX和ZygOS。它在VMX非根模式环0中运行，可以使用低开销的中断，并将控制与数据平面分离。每个低延迟应用程序在服务器上运行时都有一个单独的Shinjuku实例。

3.2 Fast Preemption

为了在微秒级别使用抢占式调度，Shinjuku需要快速的抢占。使用Linux信号通知工作进程是一种天真的方法，但是表1显示，信号会产生高开销，需要用户到内核空间的转换以及一些内核处理。

通过中断进行抢占。使用直接的处理器间中断（IPI）可能比信号更快。x86处理器使用高级可编程中断控制器（APIC）实现IPI。

每个核心都有一个本地APIC和一个连接到系统总线的I/O APIC。要发送IPI，发送核心会在其本地APIC中写入寄存器，通过I/O APIC将中断传播到目标核心的APIC，然后将执行向中断处理程序向量化。

Dune扩展了支持IPIs，通过虚拟化本地APIC寄存器。当核心A上的非根线程写入其虚拟APIC以向核心B发送中断号V时，会导致VM退出到在根模式下运行的Dune。Dune将V写入核心B的已发布中断描述符，然后使用真实的APIC向核心B发送中断242。这会导致核心B在恢复应用程序时执行VM退出到Dune中的中断处理程序，该程序将中断号V注入非根模式。

使用IPI实现抢占的基本实现比Linux信号稍快，但仍然存在显著的开销，因为发送方和接收方都需要进行VM退出。

该文研究了优化中断传递的方法，通过使用x86的posted interrupts特性，可以在不进行VM exit的情况下接收中断，从而减少接收端的开销。在接收端B上配置硬件定义的VM控制结构（VMCS）以识别中断242作为特殊的posted interrupt通知向量，并注册posted interrupt描述符。发送端A仍然会进行VM exit，但是接收端B可以直接注入中断V，从而减少接收端的开销。这种方法可以频繁地抢占工作线程，而不会显著降低有用的工作吞吐量。

通过优化中断发送，我们使用扩展页表（EPT）将其他核心的已发布中断描述符和本地APIC的寄存器映射到Shinjuku调度程序的客户物理地址空间中，从而使调度程序可以直接发送IPI而不会产生VM退出。这样可以将发送方开销降低到298个周期（在2GHz系统中为149ns），从而提高调度程序的可扩展性，使其能够每秒处理更多的请求和/或更多的工作线程（核心）。

PAGE 7

Shinjuku使用发送方和接收方优化的中断传递来支持抢占。发送方开销低，可以构建一个处理每秒数百万次调度操作的集中式抢占调度程序。接收方开销低，可以每5微秒抢占一次请求，以调度更长的请求而不浪费超过10%的工作线程吞吐量。

3.3 Low-overhead Context Switch

在处理请求时，需要在主上下文和请求处理上下文之间进行上下文切换。直接使用Linux ucontext库中的swapcontext函数会导致显著的开销，特别是在Dune进程中。swapcontext需要系统调用来设置信号掩码，这需要在Dune中进行VM退出。但是，swapcontext中的其他工作，如保存/恢复寄存器状态和堆栈指针，不需要进行系统调用。

表2评估了上下文切换优化。首先，跳过设置信号掩码可以消除系统调用，使Dune与普通Linux保持一致。但这会带来一个限制，即同一应用程序的所有任务需要共享相同的信号掩码。其次，利用主工作上下文不使用浮点（FP）指令的特点。当从请求上下文切换到工作上下文时，我们必须保存FP寄存器，因为它们可能已经在请求处理中使用，但我们不需要为工作上下文恢复它们。当从工作上下文切换到请求上下文时，我们跳过保存FP寄存器，只为请求上下文恢复它们。Shinjuku在工作核心的上下文切换中使用了最后两个选项。总成本范围从36到109个周期（对于2GHz系统为18到55ns）。

3.4 Preemptive Scheduling

新宿实现了抢占式调度策略，通过集中式调度程序和快速抢占和上下文切换机制。我们开发了两种策略，根据请求类型是否能够事先区分来区分。这些策略依赖频繁的抢占来为任何工作负载提供接近最优的尾延迟，对于低离散度的工作负载近似于c-FCFS，对于其他情况近似于PS。

单队列策略假设我们不区分请求类型，并且有一个尾延迟的服务级别协议。所有进入的请求都放在一个先进先出队列中。当工作人员空闲时，调度程序将请求分配给队列头部的工作人员。如果请求被快速处理，这个策略就像是集中的先进先出。调度程序使用时间戳来识别任何运行时间超过预定义量的请求，并且假设队列不为空，就会抢占它。请求被放回队列，工作人员被分配到当前队列头部的请求。c-PRE-SQ策略是这个单队列策略。

多队列（MQ）策略：假设网络子系统能够识别不同的请求类型，例如可以解析KVS（如Redis和RocksDB）的请求头并将简单的获取/放置请求与复杂的范围查询请求分开。每种请求类型可以有不同的尾延迟SLO。调度程序维护每种请求类型的一个队列。如果只有一个队列有挂起的请求，则此策略的操作方式与上述单队列策略相同。如果有多个队列非空，则调度程序在工作线程变为空闲或请求被抢占时必须选择一个队列进行服务。一旦选择了队列，调度程序总是从队列头部获取请求。

Shinjuku的队列选择算法受BVT启发，使用每个队列的SLO作为输入，计算每个请求已经在系统中等待的时间与其SLO的比率，选择比率最高的队列。该算法优先考虑短请求，但也会选择等待时间较长的长请求。每个队列的SLO是用户设置的参数，可以通过单队列策略来确定。这样可以保证请求类型的性能不会受到服务时间分布不同的请求的影响。

PAGE 8

Shinjuku可以通过将抢占请求放置在队列尾部来近似PS，或将其放置在队列头部来近似c-FCFS。对于多模态或重尾工作负载，应将请求放置在队列尾部，而对于轻尾工作负载，则应将其放置在队列头部。即使在轻尾分布中，也需要频繁抢占，以便Shinjuku为其他请求类型服务。c-PRE-MQ策略是这种多队列策略，其中当抢占时，两种请求类型都放置在其相应队列的队列头部。

3.5 Implementation

Shinjuku是基于Dune实现的，需要x86-64系统的VT-x虚拟化功能。我们对Dune进行了修改，代码量为1365行，Shinjuku的调度程序和工作程序代码量为2535行。网络子系统基于IX。所有代码均为C语言。

使用Shinjuku API需要注册三个回调函数：init()函数用于初始化全局应用程序状态；init per core(int core num)函数用于为每个工作线程初始化应用程序状态（例如本地变量或配置选项）；reply * handle request(request *)函数用于处理单个应用程序级请求并返回回复数据的指针。

该系统使用修改版的Linux ucontext库进行上下文管理，上下文结构包括机器特定的状态表示、信号掩码、上下文堆栈指针和将在此上下文完成执行时恢复的上下文指针。调度程序从内存池中分配上下文对象和堆栈空间，由工作线程返回请求上下文完成执行并释放。

本文介绍了一种线程间通信的方法，使用了低开销的共享内存通信方案，每对线程之间通过共享的缓存行进行通信。发送线程将要发送的数据填充到缓存行中，并设置接收者轮询的字节的值，以通知其可以读取缓存行中的数据。该方法的平均往返延迟为211个周期，调度程序发送消息的最小工作量约为70个周期。这种方法的理论上限是28 MRPS。

3.6 Discussion

硬件约束：单个调度线程可以每秒处理至少5M个请求，并且可以充分利用具有12个核心和24个超线程的完整套接字。为了将单个应用程序扩展到更高的核心和/或套接字数量，我们必须提高调度器的吞吐量。我们使用的方法是让每个调度线程处理一组工作线程，并使用NIC RSS功能将请求引导到不同的调度器。一个相对简单的硬件特性可以极大地提高调度器的可扩展性，即在不同核心之间进行低开销的消息传递机制。理想情况下，这种机制将提供两种变体，一种是抢占式的，用于调度，另一种是非抢占式的，其中消息被添加到每个核心队列中，用于工作分配。

PAGE 9

本文介绍了IX和ZygOS使用RSS来分配请求到工作线程的方法，并使用蒙特卡罗模拟计算了在增加核心数时，保持负载均衡不超过10%所需的连接数。结果显示，需要16000个连接来避免24个超线程服务器上的不平衡。然而，Shinjuku使用RSS将请求分配给调度程序，每个调度程序可以管理数十个核心，因此不需要高连接数。例如，对于2个调度程序，300个连接就足够了。当只需要一个调度程序时，即使只有一个连接，Shinjuku也可以高效运行。

Shinjuku可以支持更多的调度策略，未来的工作将探索与数据中心广泛的分析工具和在线实验工具的集成，以动态推断服务时间分布并相应地调整策略。此外，还将探索微秒级的调度策略，考虑本地性和异构性，避免上下文切换的开销。

在线服务经历负载变化，需要调整Shinjuku进程使用的工作人员数量。Shenango通过微秒级时间尺度调整应用程序之间的核心分配来解决这个问题。计划探索将两个系统集成的可能性。

Dune内核模块使用硬件虚拟化支持来隔离Shinjuku进程，Linux可以随时从Shinjuku进程中移除核心和网络队列。在Shinjuku进程内部，应用程序代码必须信任Shinjuku运行时，如果应用程序上下文在VMX非根ring 0中执行，则Shinjuku运行时必须信任应用程序代码。一个进程可以通过向特定核心发出大量中断来对另一个进程发起拒绝服务攻击。

新版Shinjuku将在ring 3中运行应用程序代码，而Shinjuku运行时将在VMX非根ring 0中运行，消除了攻击向量，开销很小。此外，这种方法可以避免应用程序代码中的错误影响运行时系统。

在线服务在多核上运行良好，通过同步来实现可扩展性。同步请求的频率较低，以实现可扩展性。禁用或允许在读写锁周围进行抢占不会影响可扩展应用的性能。我们在非线程安全代码中禁用中断，并使用安全调用(fn) API调用来简化应用程序移植。禁用中断的指令的运行时开销仅为几个时钟周期，并且不会影响Linux内核重新获取核心的能力。内存分配代码是一个特殊情况，通常使用线程本地存储来优化锁。我们预加载了禁用中断（因此禁用抢占）的C和C++库版本，在执行分配函数时可能会影响Shinjuku观察到的尾延迟。

无论在哪个系统上，包括新宿系统，任何经常使用粗粒度或争用锁的应用程序都会扩展得很差，无论调度策略如何。

4 Evaluation

PAGE 10

本文比较了三个基于Dune的系统：Shinjuku、IX和ZygOS。其中，IX使用d-FCFS，ZygOS使用近似的cFCFS来提高尾延迟。

4.1 Experimental Methodology

本文介绍了使用6台客户端和1台服务器机器进行实验的配置，它们通过Arista 7050-S交换机连接。客户端机器包括两个Intel Xeon E5-2630 CPU，使用Intel 82599ES和Solarflare SFC9020 10GbE NIC。服务器机器包括两个Intel E5-2658 CPU，128GB DRAM和Intel 82599ES 10Gb NIC。所有机器都运行Ubuntu LTS 16.0.4和4.4.0 Linux内核。进行可扩展性实验时，还使用了具有40Gb Intel XL710-QDA2 NIC和相同E5-2658双插槽机器的服务器机器作为客户端。

服务器CPU有12个核心和24个超线程，但ZygOS和IX只支持最多16个超线程。因此，大多数实验使用8个核心（16个超线程）配置。Shinjuku总是使用两个超线程用于网络子系统和调度程序。我们的结果使用Shinjuku（x）表示Shinjuku使用x-2个超线程进行工作，总共使用x个超线程。IX（x）和ZygOS（x）表示IX和ZygOS使用x个超线程，分别用于d-FCFS或c-FCFS处理。

Shinjuku使用一个简单的网络子系统，将网络处理与请求调度分离。它可以与其他实现不同传输协议的系统结合，并使用多线程堆栈或将网络处理卸载到智能网卡等优化。如果智能网卡通过像Intel的UPI这样的一致互连连接到处理器芯片，还可以将Shinjuku调度程序卸载到网卡核心上。

IX支持UDP和TCP网络。我们使用UDP和批处理大小为64。ZygOS仅支持TCP网络，但配置为每个请求和回复使用一个TCP段。因此，ZygOS请求在TCP处理方面有一些额外的服务时间（<0.25微秒），但与基于UDP的IX和Shinjuku请求类似。

本文介绍了使用一个合成和一个真实的工作负载来比较三个系统的性能。合成工作负载是一个服务器应用程序，请求执行虚拟工作，可以控制以模拟任何目标服务时间分布。这个合成服务器允许我们洞察三个系统在大型应用程序空间中的比较。

本文介绍了三个系统：IX、ZygOS和Shinjuku，它们都使用了RocksDB 5.13作为键值存储。这些系统处理的查询可能是简单的get/put请求或范围扫描。为了在最低延迟要求下评估这三个系统，我们将RocksDB配置为将所有数据保存在DRAM中。如果一些RocksDB请求必须访问Flash中的数据，则服务时间的变异性将更高，而抢占式的Shinjuku将比非抢占式的IX和ZygOS表现得更好。

我们开发了一个类似于mutilate的开放式负载生成器，可以通过TCP或UDP传输请求。负载生成器在一组客户端机器上启动大量连接，同时从单个未加载的机器上测量延迟。除非另有说明，我们使用1920个持久的TCP连接（ZygOS）和1920个不同的UDP 5元组（IX和Shinjuku）。使用较少的连接会显著影响IX和ZygOS的性能（见§3.6）。

4.2 Synthetic Workload Comparison

本文比较了Shinjuku、IX和ZygOS在三种服务时间分布下的性能。在服务时间固定为1微秒的情况下，IX使用d-FCFS和批处理请求的能力表现最佳。Shinjuku使用两个超线程进行网络和调度，对超过5微秒的请求进行抢占，但仍能表现接近IX。ZygOS的性能下降较为明显，即使在同质工作负载下也有较高的窃取率。

PAGE 11

本文介绍了三种操作系统在处理Bimodal服务时间分布时的性能表现。Shinjuku采用单队列策略，能够在低负载下实现高达50%的低尾延迟和5倍的吞吐量。相比之下，IX和ZygOS缺乏抢占机制，无法有效处理长请求，导致短请求频繁被阻塞。ZygOS的任务窃取机制虽然有所改进，但仍无法应对服务时间分布的高离散性。Shinjuku采用抢占机制，将长请求放在队列尾部，以便快速完成短请求。

本文介绍了一个名为Shinjuku的新型操作系统，它采用了一种新的多队列策略，可以在多种请求类型的情况下提高系统性能。实验结果表明，Shinjuku在低负载下的请求延迟比IX和Zygos低94%，吞吐量也提高了2倍以上。Shinjuku的优势在于其能够根据请求的排队时间和目标延迟选择下一个服务的请求类型。

4.3 Shinjuku Analysis

在Bimodal(50-1,50-100)合成工作负载中，Shinjuku使用多队列策略，频繁的抢占间隔对其性能影响很大。抢占间隔越短，Shinjuku的表现越好，因为100微秒请求对1微秒的影响减小了。即使在非常频繁的5微秒抢占间隔下，Shinjuku的表现也很好。

PAGE 12

本文介绍了Shinjuku的扩展性能。通过使用Intel XL710-QDA2 40Gb NICs，每个工作线程可以饱和其核心，关闭超线程并将每个工作线程固定到物理核心。单个调度程序线程几乎线性地扩展到11个工作核心，第二个调度程序线程允许Shinjuku在两个插座上调度22个工作核心。使用两个调度程序，Shinjuku可以调度1个应用程序的5M和9.5M RPS。Shinjuku在回复帧长度为258字节时饱和40Gb NIC的出站网络吞吐量。

这两个图表证明了单个新宿应用程序可以扩展到高核心数和高线路速率，即使服务时间只有1微秒。

4.4 RocksDB Comparison

该文介绍了使用RocksDB在IX、ZygOS和Shinjuku上实现的简单服务器。服务器使用/tmpfs/上的随机键值对创建的RocksDB数据库来处理客户端请求，包括GET请求和SCAN请求。为了避免内存复制和块设备访问，使用内存映射的普通表作为后备文件。Shinjuku使用15微秒的抢占时间片，并将被抢占的请求放置在多队列策略的相应队列的头部，单队列策略的相应队列的尾部。

Shinjuku在尾延迟和吞吐量方面相比ZygOS有显著改进，尾延迟减少了88%，吞吐量提高了6.6倍。Shinjuku通过频繁的抢占，使得GET请求避免了由于SCAN请求导致的长时间排队。IX由于请求服务时间不平衡和d-FCFS调度的组合而表现更差。

PAGE 13

本文研究了调度策略对于系统性能的影响。实验结果表明，Shinjuku调度器在没有抢占的情况下，更倾向于长时间的SCAN请求，而加入抢占机制后，可以实现公平的吞吐量和低延迟。多队列抢占策略可以进一步提高SCAN请求的性能。相比之下，ZygOS表现较差，因为其使用分布式队列，容易出现请求阻塞的情况。因此，Shinjuku调度器将网络处理和请求调度分离是一个明智的决策。

5 Related Work

网络协议栈的优化工作包括轮询处理、多核可扩展性、模块化和专业化以及操作系统绕过等，而Shinjuku则是在网络协议处理后优化请求调度的。

最近的一些数据平面操作系统通过将操作系统数据平面与控制平面分离来优化吞吐量和尾延迟。这些系统包括IX、Arrakis、MICA、Chronos和ZygOS。Shinjuku通过引入抢占式调度来改进这些系统，使得短请求能够避免过多排队。

Li等人通过减少长时间运行的请求所占用的资源来控制尾延迟，而Haque等人则采取相反的方法，将更多资源分配给滞后者，以便更快地完成任务。Shinjuku允许开发有效的调度策略，适用于比这一领域能处理的任务短3个数量级的请求。

PIAS是一种网络流调度机制，利用交换机中的硬件优先级队列来近似最短作业优先（SJF）调度策略，并优先处理短流量而不是长流量。然而，在Shinjuku中我们不采用类似的方法，因为SJF在最小化平均延迟方面是最优的，但不是尾延迟。此外，为了有效，PIAS需要一种形式的拥塞控制来保持队列长度短。在非网络环境中，这在运行时无法控制应用程序，因此不实用。

ELI引入了安全、低开销的中断概念，用于快速将中断传递给虚拟机。ZygOS使用处理器间中断进行工作窃取，但不实现抢占式调度。Shinjuku使用Dune优化处理器间中断。

用户空间线程管理：从调度激活开始，有几个努力实现高效的用户空间线程库，它们都专注于协作调度。Shinjuku表明，抢占式调度在微秒级别是实用的，可以实现低尾延迟和高吞吐量。

6 Conclusion

Shinjuku使用虚拟化的硬件支持，使得微秒级的频繁抢占成为可能，避免了非抢占策略中短请求被长请求阻塞的常见问题。Shinjuku提供了低尾延迟和高吞吐量，适用于各种分布和请求服务时间，无论客户端连接数量如何。对于RocksDB KVS，Shinjuku在吞吐量和尾延迟方面比最近发布的ZygOS系统提高了6.6倍和88%。

Acknowledgements

我们感谢我们的牧羊人Irene Zhang和匿名的NSDI审稿人对我们的有益反馈。我们还感谢John Ousterhout、Adam Wierman和Ana Klimovic对本文早期版本的反馈。这项工作得到了斯坦福平台实验室的支持，并得到了Google、华为和三星的赞助。
