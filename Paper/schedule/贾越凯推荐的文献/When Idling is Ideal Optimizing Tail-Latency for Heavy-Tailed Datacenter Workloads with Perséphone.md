微软研究，英国，Joshua Fried。

Isaac Pedisich是美国微软研究部门的研究员。

Abstract

本文介绍了Perséphone，一种旨在最小化微秒级应用程序尾延迟的内核旁路操作系统调度程序。Perséphone集成了一种新的调度策略DARC，该策略为具有短处理时间的请求保留核心。与现有的内核旁路调度程序不同，DARC不是工作保留的。DARC对应用程序请求进行分析，并在队列中没有短请求时保留少量核心，因此当短请求到达时，它们不会被长时间运行的请求阻塞。留出核心让DARC在更高的利用率下保持较低的尾延迟，减少了为服务相同工作负载所需的总核心数，从而更好地利用数据中心资源。

计算机系统组织。

本文讨论了Kernel-bypass和Scheduling的相关问题。

ACM Reference Format:

本文介绍了一种名为Perséphone的系统，它可以通过空闲时间来优化重尾数据中心工作负载的尾延迟。该系统使用了一种新颖的方法，即在空闲时间内执行任务，以减少尾延迟。实验结果表明，Perséphone可以显著降低尾延迟，并提高系统吞吐量。

1 Introduction

现代云应用需要具备微秒级的延迟，以满足大规模数据中心后端服务器的需求。在微秒级的处理时间中，请求处理时间的分布可能非常极端。因此，单个长时间运行的请求可能会阻塞数百个或数千个其他请求。

为了限制尾延迟，现代数据中心服务器运行在低利用率下，以保持队列短并减少短请求被长请求阻塞的可能性。然而，这种方法浪费了宝贵的CPU周期，并不能保证微秒级数据中心系统总是能满足短请求的SLO。

近期，谷歌、微软和亚马逊等公司都在优化其云计算平台的利用率，采用了共享队列和工作窃取等技术。但这些技术只适用于响应时间分布较为均匀的工作负载。对于响应时间分布较宽的工作负载，Shinjuku 利用中断实现处理器共享，但这会对单个微秒请求产生不可忽略的延迟，并且成本较高。此外，Shinjuku 的非标准硬件虚拟化特性使其难以在数据中心和公共云中使用。

最近的拥塞近似算法SRPT可以优化网络利用率，减少流完成时间，最小化平均等待时间。与CPU调度不同，交换机数据包调度器有物理的“抢占”单元，可以根据流大小优先处理数据包头，使调度决策和策略执行更容易。CPU调度器无法预先知道每个请求将占用CPU的时间，也没有执行时间上限，这使得微秒级别的请求实现变得困难。

PAGE 2

本文介绍了一种针对重尾流和请求分布的CPU调度方法，通过应用感知技术和现代多核服务器的并行性和核心丰富性来实现。该方法与Homa等拥塞控制方案和Shinjuku等CPU调度器不同，它利用并行性和多核心的优势，避免了共享资源的临时复用。

首先，内核绕过调度器可以识别请求类型。其次，相同类型的请求通常具有相似的处理方式，因此可以通过追踪过去的每种类型的处理时间来预测未来的处理时间。最后，我们会留出空闲核心，以防止短请求排在任意长的请求之后。

本文研究了数据中心网络的调度问题，提出了一种与传统操作系统调度器不同的方法，通过牺牲最大可达吞吐量，提高了在严格延迟服务水平下的可达吞吐量，从而提高了整体CPU利用率。

Pers éphone是一种应用程序感知的内核旁路调度器，可以让应用程序定义请求分类器，并使用这些分类器动态地对工作负载进行分析。它实现了一种新的调度策略DARC，可以在保留能够处理到达突发请求的能力的同时，有效地将CPU资源分配给不同类型的请求。DARC优先处理短请求，适用于需要微秒级响应的应用程序。在实验中，DARC的吞吐量仅降低了5%。对于其他应用程序，现有的内核旁路调度器也能很好地工作。

本文使用DPDK对Perséphone进行原型设计，并与两种最先进的内核旁路调度器Shinjuku和Shenango进行比较。通过使用多样化的工作负载，我们展示了使用DARC的Perséphone可以显著提高请求尾延迟，并在目标SLO下承载比Shenango和Shinjuku分别多2.3倍和1.3倍的负载。此外，这些改进对于长时间请求的成本比Shinjuku的抢占技术更低，突显了传统操作系统调度技术在微秒级别上的挑战。

2 The Case for Idling

当工作负载具有广泛的服务时间分布时，长请求可以占用所有工作人员的时间，从而阻塞短请求，即所谓的基于分散的头部阻塞。为了更好地理解分散阻塞对短请求的影响，我们研究了减速：在服务器上花费的总时间与纯应用程序处理时间的比率。

长请求对短请求的影响体现在减速上。对于重尾工作负载，短请求的减速与尾部长度成正比。具体来说，考虑以下工作负载，类似于Zygos的“bimodal-2”，99.5%的短请求运行时间为0.5微秒，0.5%的长请求执行时间为500微秒。一个被长请求阻塞的短请求可能会经历高达1001的减速，而一个被短请求阻塞的长请求将会看到1.001的减速。因此，少数被长请求阻塞的短请求将推动减速分布并增加尾延迟。

本文模拟了四种调度策略，包括分散式先进先出（d-FCFS）、集中式先进先出（c-FCFS）、时间共享（TS）和 DARC。d-FCFS 模型使用本地队列，每个工作进程平均接收所有传入的流量；c-FCFS 使用单个队列接收所有请求并将其发送到空闲工作进程；TS 使用多个队列处理不同类型的请求，并使用微秒级别的 Dune 中断。本文模拟了这些策略，并提供了相应的实现细节。

本文模拟了一个理想的系统，没有网络开销，使用16个工作人员，模拟了1秒钟的泊松分布请求，并报告了不同利用率下的99.9%请求类型的观察到的减速情况，最大达到5.3百万请求/秒。

PAGE 3

本文介绍了数据中心服务器调度算法的优化。传统的d-FCFS和c-FCFS算法都存在缺陷，无法有效地处理请求。Shinjuku的TS策略表现更好，但存在实际可行性问题。作者提出了DARC算法，通过预留一部分核心处理短请求，可以有效降低延迟。该算法需要应用程序的支持，但可以显著提高服务器性能。

DARC可以在5.1 Mrps的负载下满足10倍的慢速请求SLO目标。这比c-FCFS和乐观廉价的时间共享策略的可持续吞吐量分别多出2.5倍和1.4倍。在这个负载下，短请求的p99.9尾延迟为9.87微秒，比c-FCFS和TS分别小了3个和1个数量级，分别为7738微秒和161微秒。为了实现这一点，DARC要求程序员提供一个请求分类器来识别类型，并使用该分类器动态估计请求的CPU需求。在这个例子中，DARC为短请求保留了1个工作线程，但吞吐量会有5%的小幅度下降。

PAGE 4

DARC虽然会浪费一些时间，但它可以减少服务器的数量，因为服务器可以以更高的利用率运行，同时保持短和长请求的良好尾延迟。

3 DARC Scheduling

该资源旨在满足DARC的需求，提高云工作负载中单位微秒请求的尾延迟，而无需抢占。通过提取请求类型、了解CPU需求并分配足够的资源，保护后端服务器上的短请求。类似于最近的网络技术，通过协同设计网络协议和网络交换机的优先级队列管理来优先处理小消息。

本节讨论了将这些技术作为CPU调度策略实现时所面临的挑战，并介绍了DARC调度模型，以及如何计算预留量和何时更新它们。表2描述了相关内容。

保护短请求的难点在于需要预测每种请求类型占用CPU的时间，并在保持处理突发到达的能力和最小化CPU浪费的同时，将CPU资源分配给不同的请求类型。这需要使用优先队列和非工作守恒的动态方式。

DARC面临的第一个挑战是处理微秒级的操作，并且需要对工作负载的变化做出反应。为了解决这个问题，我们使用低开销的工作负载分析和排队延迟监控的组合方法，前者用于构建请求的CPU需求指纹，后者作为指示该指纹可能已经显著改变的信号。本节描述了该技术，第4节描述了其实现。

该挑战包括两个方面：突发容忍度和CPU浪费。通过减少给定请求类型的可用核心数量，可以防止其对其他类型产生负面影响，但也会降低其吸收到达突发的能力。为了解决这个问题，我们采用了从短类型到长类型的循环窃取机制，使短请求可以在本来为长请求保留的核心上执行。这种机制的理由是短请求相对于长请求造成的减速较小。需要注意的是，循环窃取类似于工作窃取，但实际上不同，因为它是从DARC调度程序而不是应用程序工作者执行的（因此不需要昂贵的跨工作者协调）。

DARC是一个分布式系统，需要处理多种请求类型，但请求类型数量可能与CPU核心数量不同，因此需要确定共享或不共享CPU核心的策略。为了解决这个问题，DARC采用了类型分组和溢出核心机制。类型分组可以让所有请求类型适合有限数量的核心，减少分数绑定的数量，同时保留根据处理时间分离类型的能力。溢出核心允许DARC始终为平均CPU需求较小的类型提供服务。

DARC是一个调度模型，它使用单一队列抽象来处理应用程序工作。它按照平均服务时间对类型队列进行排序，并按照先到先服务的方式出队列。除了在保留核心上调度给定类型的请求外，还可以从分配给较长类型的核心中窃取周期。DARC使用了Cycle Stealing with Central Queue（CSCQ）的概念，这是一种用于计算集群的作业调度策略。算法1描述了工作选择的过程。对于系统中注册的每个请求类型，如果该类型的队列中有待处理的请求，DARC会贪婪地搜索保留工作器列表，寻找空闲的工作器。如果找不到，则DARC会搜索可窃取的工作器。如果找到了空闲的工作器，则将类型队列的头部分派给该工作器。当工作器完成一个请求时，它会向DARC调度程序发送完成信号。

该文研究了如何为不同的请求类型分配资源，以满足服务水平目标。基于峰值负载下的平均CPU需求来确定请求类型的资源需求，使用平均需求是因为它是系统稳定性的可证明指标。通过计算工作负载的组成，将每个请求类型的平均服务时间归一化，以计算平均CPU需求。具体而言，给定一组N个请求类型，每个请求类型的平均CPU时间需求取决于其服务时间和出现比例。

PAGE 5

给定一个系统有W个工人，这意味着我们应该将Δi * W个工人归属于τi。

因为CPU需求可以是小数，并且我们对系统设置了非抢占性要求，所以我们需要一种策略来将CPU的小数部分分配给请求类型。对于每个这样的“小数关系”，我们必须做出选择：要么向上取整并始终授予整个核心，要么向下取整并将小数部分的CPU需求合并到共享核心上。前者可能会导致某些类型的过度配置，而以其他类型的核心为代价，而后者可能会通过将长期和短期请求混合到一起而产生基于分散的阻塞。

我们的方法结合了两种策略：首先，我们通过将相似处理时间的请求类型分组，并计算整个组的CPU需求来减少“分数绑定”的数量；其次，我们对这个需求进行四舍五入。因此，对于𝐺个组，如果𝑓𝑖是组𝑖的分数需求，DARC在所有𝐺个组中的平均CPU浪费是：

该文本讨论了一种名为“工作窃取”的并行计算技术，它可以提高CPU利用率和系统吞吐量。该技术通过将任务分配给空闲的CPU核心来实现负载均衡，并通过工作保留来减少CPU浪费。在高负载情况下，该技术可以通过选择性启用工作保留来减少CPU浪费。

算法2描述了预订过程。首先，我们识别出平均服务时间相差不超过𝛿倍的相似类型。然后，根据每个组的需求计算需求量，并相应地分配工人，同时进行四舍五入。我们总是至少分配一个工人给一个组。DARC分组策略仍可能导致较早的组-较短的请求-消耗所有CPU核心。为了为这些组提供服务，我们设置了“溢流”核心。如果没有更多的空闲工人，next_free_worker()将返回一个溢流核心。在我们的实验中（第5节），我们使用一个溢流核心。

DARC通过选择性启用工作保护来更好地处理短请求的突发情况，同时让每个组从尚未保留的工作人员中窃取，从而更好地处理工作负载的尾延迟。

DARC是一种用于处理多种工作负载的调度算法，它使用分组技术来处理不同类型的请求。它优先处理服务时间较短的请求，并且可以通过溢出核心来避免拒绝长时间请求。操作员可以调整分组因子来调整非工作保护以满足他们的SLO。

DARC调度器在运行时使用分析窗口来维护关于每个请求类型的两个信息：服务时间的移动平均值和发生比率。调度器在应用程序工作完成时收集这些信息。调度器使用排队延迟和CPU需求的变化作为性能信号。如果前者超过目标减速SLO，并且后者与当前需求显著偏离，调度器将更新请求类型的配置文件和预留资源。在启动时，系统使用c-FCFS，并收集样本，然后过渡到DARC。这种技术使得DARC能够应对不断变化的工作负载，其中未知或意外的请求可以使用溢流核心来执行。我们在第4.3.3节讨论了该机制的敏感性。

4 Pers éphone

PAGE 6

DARC是一种无需特殊硬件或应用程序修改的调度算法，可以在Perséphone内核旁路调度程序中实现。为了支持微秒级内核旁路应用程序，Perséphone必须满足以下要求：（1）网络堆栈必须能够在数据路径中高效地按类型对请求进行排序，（2）调度程序必须能够快速进行每个请求的调度决策，（3）用于更新DARC预留的工作负载分析必须具有低开销。

Pers éphone满足了三个要求：请求分类器API、网络堆栈、分析器和调度器。请求分类器可以根据请求类型对请求进行分类。网络堆栈、分析器和调度器被打包在一个用户级库中。

4.1 System Model

Perséphone是为数据中心服务设计的，可以处理大量流量和微秒级延迟的应用程序，例如键值存储、快速推理引擎、Web搜索引擎和RESTful微服务。它使用内核旁路以实现低延迟I/O，并通过Perséphone执行所有应用程序和网络处理。当前原型设计用于UDP网络，但该技术也适用于有状态调度程序。

4.2 Request classifiers

Pers éphone是一个根据用户定义的请求对其进行分类的系统。它接受一个应用负载的指针，并返回一个请求类型。如果无法识别请求，它将将其归类为UNKNOWN并放入低优先级队列。当前设计中最多只能有一个活动的分类器。尽管大多数目标应用程序使用优化的协议，如Redis的RESP，允许分类器查找头字段以解析请求类型，但我们选择了通用性，并允许用户编写任意复杂的分类器。当然，这会带来性能上的权衡：非优化的请求分类器会影响调度器的性能，因为现有的请求分类器是“绕过内核”的“调度器”。我们将其留给用户根据他们希望从调度器获得的性能（即每秒能够处理多少个请求）来量化这种权衡。虽然对分类器性能的完整研究超出了本文的范围，但我们发现，在标准协议中，如果请求类型在头部中的位置已知，我们的调度器在我们的测试平台上可以处理高达700万个数据包每秒，这个数字与其他竞争系统相当。

4.3 Pers éphone Architecture

Perséphone由三个组件组成：网络工作者从网络卡中出队数据包，调度程序应用请求分类器并执行DARC调度，应用程序工作者执行应用程序处理。这些组件作为事件操作。

该流水线以驱动方式运行，按以下方式处理数据包。第一步是在...

网络工作人员从网络中接收数据包。

该系统接收用户请求并将其推送给调度程序，调度程序使用用户定义的请求分类器对请求进行分类。

3个商店使用特定的队列来存储，即专门用于存储的缓冲区。

本文介绍了一个名为DARC的分布式系统，它可以处理单一请求类型。其中，调度程序运行DARC。

从一个已输入的队列中选择一个请求并将其推送到一个空闲的位置。

应用程序工作人员处理请求。

该段文字提到了一个应用程序工作器，它格式化响应缓冲区并将指针推送到NIC。同时，它还提到了6个推送指针的操作。

机器人完成请求后通知调度员。

Perséphone在初始化时为网络和应用程序工作线程提供了网络上下文，以便它们可以访问NIC中的接收和传输队列。Perséphone还为上下文注册了一个静态分配的内存池，以便快速分配新的缓冲区。工作线程使用本地缓存来减少与主内存池的交互。如果请求包含在单个应用程序级缓冲区中，我们执行零拷贝并将指向网络缓冲区的指针传递给工作线程。如果请求跨越多个缓冲区，则需要复制。如果请求在单个数据包中，则工作线程重用入口网络缓冲区来承载出口数据包，从而减少使用的不同网络缓冲区的数量。

PAGE 7

调度程序使用单生产者、单消费者的循环缓冲区来与应用程序工作线程共享请求和命令，采用无锁交互模式。发送方和接收方使用共享变量来同步发送/读取头部，采用受Barrelfish启发的轻量级RPC设计。为了减少核心之间的缓存一致性流量，发送方仅在本地状态显示缓冲区已满时与接收方同步，以更新读取头部并避免溢出。在我们的原型中，该通道上的操作平均需要88个周期。

调度程序维护三个主要的数据结构：请求类型对象列表、类型化请求队列和空闲工作线程列表。调度程序还持有指向用户定义的请求分类器的指针。空闲工作线程列表在每次调度请求时更新，并在应用程序工作线程通知调度程序工作完成时更新。调度程序还维护性能分析窗口，通过请求类型计算服务时间的移动平均值，并为每个类型增加一个计数器。DARC使用这些性能分析窗口来计算资源分配并适应工作负载组成的变化。在原型中，更新请求的性能分析需要75个周期，检查是否需要更新需要约300个周期，执行预留更新需要约1000个周期。

本文介绍了一个高性能的分布式键值存储系统，其中包括了调度器、工作线程和应用程序工作者。调度器负责将请求分配给工作线程，工作线程负责处理请求并将响应发送回客户端。应用程序工作者通过访问请求类型对象来优化处理请求的逻辑。系统还采用了流量控制和更新机制来控制工作负载。

5 Evaluation

我们使用3700行C++代码构建了Perséphone的原型，以评估DARC调度与Shenango和Shinjuku提供的策略。

在短请求和长请求之间有100倍的差异的工作负载下，Perséphone相比Shenango和Shinjuku可以分别支持2.35倍和1.3倍的吞吐量。

Perséphone在1000倍离散负载下，比Shenango能够承受1.4倍的吞吐量，并且对于短请求，能够比Shinjuku提高1.4倍的减速。

Perséphone在TPC-C基准测试中，相比Shenango和Shinjuku，可以将减速降低4.6倍和3.1倍。

DARC在RocksDB应用中的吞吐量比Shenango和Shinjuku分别高出2.3倍和1.3倍。

Perséphone可以处理工作负载快速变化和程序员提供错误请求分类器的对抗情况。

5.1 Experimental Setup

工作负载可以展现不同的服务时间分散性，常见的是呈现多峰分布，其中有相等数量的短请求和长请求，或者大多数是短请求但也有少量非常长的请求。短请求和长请求之间的分散性通常是两个数量级以上。我们评估了两种展现大的服务时间分散性的工作负载（High Bimodal和Extreme Bimodal），以及模拟电子商务的标准OLTP模型TPC-C的请求。

PAGE 8

DARC使用RocksDB作为内存存储引擎，RocksDB是Facebook使用的数据库引擎。

本文介绍了三种不同的请求分布模式，分别是高双峰、极端双峰和RocksDB。通过对TPC-C事务和RocksDB工作负载的评估，展示了Perséphone在不同请求分布模式下的性能表现。其中，高双峰和极端双峰的请求分布模式分别对应长请求占比50%和0.5%，且极端双峰的长请求比高双峰慢1000倍。RocksDB工作负载则是由50%的GET请求和50%的SCAN请求组成，执行时间分别为1.5微秒和635微秒，呈现出420倍的差异。

我们提供了两种性能指标：（i）实验中所有请求的尾部减速度，以及（ii）类型的尾部延迟，即仅针对类型的响应时间分布选择的百分位数。这些指标帮助我们理解系统和策略在评估中提供的各种权衡。对于这两个指标，我们使用99.9th百分位数，并将它们作为系统的总负载的函数进行绘制。

该客户端是一个C++开放式负载生成器，模拟突发生产流量的行为。每个实验运行20秒，丢弃前10％的样本以消除热身效应。与服务器交互时，使用简单的协议将TPC-C事务ID，RocksDB查询ID和合成工作负载请求类型放置在请求头中。请求分类器将这些ID映射到请求类型。该请求分类器为每个请求添加一次性约100纳秒的开销。

本文介绍了三个系统：Perséphone、Shenango和Shinjuku。其中，Shenango的IOKernel使用RSS哈希将数据包导向应用程序核心，通过工作窃取来平衡负载和避免基于分散的阻塞。

本文比较了Shinjuku、Shenango和ZygOS三个系统的性能。Shinjuku实现了微秒级用户级抢占，并采用单队列和多队列策略。Shenango禁用了工作窃取，以评估d-FCFS。本文选择Shenango而非ZygOS，因为Shenango支持UDP。DARC在请求经历排队延迟达到其平均服务时间的十倍时更新预留。所有系统均使用UDP网络。

测试平台：使用7个Cloudlab c6420节点，每个节点配备一个16核（32线程）的Intel Xeon Gold 6142 CPU，运行频率为2.60GHz，376GB的RAM和一个Intel X710 10 Gigabit NIC。机器之间的平均网络往返时间为10微秒。禁用了TurboBoost和设置了isolcpu。Shinjuku和Perséphone运行在Ubuntu 16.04上，Linux内核版本为4.4.0。Shenango运行在Ubuntu 18.04上，Linux内核版本为5.0。Shinjuku使用一个超线程用于网络工作线程，另一个超线程用于调度器，它们位于同一个物理核心上。Shenango在一个单独的核心上运行其IOKernel，Perséphone在同一个硬件线程上运行其网络工作线程和调度器。所有系统都使用14个运行在专用物理核心上的工作线程。对于Shenango，我们在启动时为所有核心分配资源，并禁用动态核心分配，因为我们想评估单个应用程序的性能，而Shenango会将核心重新分配给在同一台机器上运行的多个应用程序。

5.2 DARC versus existing policies

DARC在处理短请求时相比于c-FCFS和d-FCFS能够提高性能。c-FCFS通过消除工作节点上的本地热点来改善短请求的尾延迟，这与之前的研究结果一致。然而，由于c-FCFS无法保护短请求的服务时间分布，它们会受到长请求的分散性阻塞。与c-FCFS相比，DARC为短请求保留了一个核心并将它们优先调度，从而将整个工作负载的减速因子降低了15.7倍，并且可以在短请求的20微秒SLO下维持2.3倍的吞吐量。这样做的代价是长请求的尾延迟增加了最多4.2倍。DARC造成的平均CPU浪费为0.86个核心。由于减速是由短请求驱动的，并且两个图形非常相似，我们在接下来的部分中省略了短请求，并专注于整体减速和长请求的尾延迟。

5.3 How much non work-conservation is useful?

PAGE 9

DARC的预留机制得到了实证验证，称为DARC-static。当预留工人数为0时，它等同于简单的固定优先级。它首先安排短请求，并让它们在所有核心上执行。

该研究表明，对于高双峰和极端双峰的负载，DARC策略中短请求的优先级更高。在95%的负载下，对于前者，使用1个核心可以实现4.4倍的最佳减速，对于后者，使用2个核心可以实现1.5倍的最佳减速。这些结果验证了DARC的选择。

对比而言，cFCFS在Perséphone上提供了减速线。预留过多的工人会导致长请求被饿死。简单固定优先级调度会导致基于分散的阻塞对短请求。

5.4 Comparison with Shinjuku and Shenango

本文介绍了High Bimodal和Extreme Bimodal在三个系统中的性能表现，包括TPC-C和RocksDB。Shenango实现了d-FCFS和c-FCFS，Shinjuku使用了多队列策略和单队列策略。作者在短请求性能和尽可能频繁地抢占方面对Shinjuku进行了调整。Shinjuku对TPC-C最有利，可以处理85%的负载。作者发现减少抢占的频率可以在牺牲短请求的情况下维持更高的负载。

Shinjuku通过抢占长请求来改善短请求的尾延迟，但是它每5微秒就会进行一次抢占，给被抢占的请求增加了至少20%的开销。因此，它只能承载75%的负载，而DARC则为短请求保留了一个核心，并且可以承载比Shenango和Shinjuku分别多2.35倍和1.3倍的负载。在75%的负载下，DARC相比Shenango和Shinjuku分别减少了10.2倍和1.75倍的延迟。此外，与Shinjuku的抢占系统相比，DARC始终为长请求提供更好的尾延迟。此外，我们还观察到Perséphone的集中调度对于长请求的性能优于Shenango，因为Perséphone不需要通过工作窃取来近似集中调度。

Shinjuku和Perséphone在高负载下比Shenango更能承受50倍的减速，但Shinjuku在55%以上的负载下会出现丢包。Perséphone为短请求保留了2个核心，可以承受更高的负载并减少减速，同时提供与Shenango相当的长请求尾延迟。DARC造成的CPU浪费平均为0.67个核心。

PAGE 10

DARC在TPC-C负载中将交易分为三组，并将工作人员分配给这些组。DARC强烈支持来自A和B组的较短交易。与Shenango的c-FCFS相比，DARC为Payment、OrderStatus和NewOrder交易提供了更好的尾延迟，分别提高了9.2倍、7倍和3.6倍。这些交易占负载的92%，导致减少了4.6倍的减速。

PAGE 11

DARC通过优先级调度，能够在高负载下保持较好的尾延迟，并在NewOrder请求方面表现出色。与此相比，Shinjuku对Delivery和StockLevel请求进行了重复抢占，导致性能下降。与Shinjuku相比，DARC能够在高负载下更好地平衡Delivery和StockLevel请求，并将减缓速度降低了3.1倍。

Perséphone的吞吐量比Shenango高1.2倍，比Shinjuku高1.05倍，目标是总体放慢10倍。

本文介绍了使用Perséphone构建运行RocksDB的服务，并创建了一个类似的RocksDB服务的Shenango应用程序。实验结果表明，DARC可以比Shenango和Shinjuku分别提高2.3倍和1.3倍的吞吐量，以实现20倍的减速QoS目标。

5.5 Handling workload changes

本节展示了Perséphone对工作负载组成突然变化的反应能力。与基准线c-FCFS性能进行比较。实验研究了三种阶段变化：（1）快速请求突然变慢，反之亦然；（2）每种类型的比例变化；（3）工作负载变为仅包含快速请求。在整个实验中，我们将服务器利用率保持在80%。每个阶段持续5秒。图7显示了结果。绿色框表示阶段。第一行是99.9th百分位延迟，第二行是每种类型保证的核心数（不包括可偷取的核心）。

实验开始时，B请求可以在14个核心上运行，其中1个核心专用，13个核心可被共享。A请求可以在13个核心上运行。在实验的第二阶段中，我们反转了A和B的服务时间，以评估DARC如何处理错误分类。在过渡期间，B请求的延迟增加了，因为在更新预留之前，“A-slow”请求被允许在所有核心上运行。在第二次过渡中，我们改变了每种类型的比例，A请求现在占总数的99.5%。结果，他们的CPU需求增加，DARC为他们预留了2个核心。对于这种新的组合，服务器的80%利用率会导致吞吐量增加，同时两种类型的请求的延迟略有增加。

PAGE 12

工作负载改为只有A请求，B请求可以在溢出核心上服务。

5.6 Random classifier

本文研究了DARC调度算法在不同情况下的表现。在正确分类请求的情况下，DARC表现良好，比传统的c-FCFS算法更优。在用户未提供正确分类器的情况下，DARC-random和c-FCFS表现相似。

6 Discussion

工作人员网络是一个分层模型，其中2个转发器在当前实现中执行简单的以太网和IP头的检查。应用程序工作人员处理第4层及以上，并直接执行TX。这种设计旨在最大化调度程序的性能，这是Perséphone中的主要瓶颈，并使其与现有系统竞争。Shenango和Shinjuku以类似的方式分离角色。然而，没有根本的理由不让网络工作人员处理更多的网络堆栈。使用有状态的网络堆栈将阻止将TX卸载到工作人员，因为网络工作人员和应用程序工作人员之间的共享状态将影响性能。对于TCP，TAS [53]和Snap [62]在一定程度上解决了这个问题。

本文讨论了在微秒级别上实现中断的挑战，包括操作开销和保护短请求的关键时机。通过模拟不同中断开销和延迟的单队列抢占系统，发现即使只有1微秒的开销也会导致30%的可持续负载下降。为了解决这些挑战，DARC提出了一种补充资源分区技术。同时，抢占还需要重新设计应用程序以确保不会在关键部分发生。

DARC数据中心可以与生态系统合作，适应负载变化并在此类事件期间更新预订。在系统超载的情况下，DARC将尽可能优先处理短请求，首先触发长请求的流量控制。

7 Related work

PAGE 13

过去五十年来，内核绕过和应用定制的绕过服务一直受到关注。一些著名的例子包括RC 4000多程序系统、Hydra、Mach、Chorus、SPIN和Exokernel。

最近，网络速度的提升和CPU速度的停滞使得研究人员更加关注用户级网络堆栈、高性能存储系统、分离内存访问、用户级网络服务和快速I/O处理。用户级调度也得到了探索，通过实施集中调度策略和用户级抢占来改善尾延迟。DARC建立在这些研究的基础上，通过共享应用级信息和常见情况服务加速来提高重要请求的尾延迟。DARC的多队列策略可以与现有的内核绕过调度器集成，程序员可以决定是否为他们的工作负载提供请求分类器。

本文比较了DARC与现有的进程或数据包调度策略，并确定了最适合每种策略的情况。DARC与固定优先级调度和循环窃取中央队列等策略有相似之处，但不会对较短请求的窃取施加限制。DARC针对高服务时间差异的应用程序，类似于处理器共享策略，但DARC是第一个应用感知且非抢占式的策略，可以在服务微秒级请求的内核旁路系统上实现。现有的工作已经利用了非工作保守性来减少SMT架构中的资源争用，但重点是指令吞吐量而不是数据中心的尾延迟。

In-network end-host scheduling. R2P2 [56] and

本文介绍了几种网络调度技术，包括Metron、Loom、eRSS、RSS++和ADQ等。本文提出的DARC技术可以将请求分类器卸载到网络中，与其他技术不同。此外，最近的网络硬件进展使得DARC可以在可编程交换机或直接在终端主机硬件中实例化。

网络调度对于尾延迟非常重要。先前的研究已经广泛探讨了通过优先级队列来改善尾延迟的方法。这些方法使用了最短剩余处理时间（SRPT）调度来避免FIFO策略引起的头部阻塞。与网络设备以数据包为粒度进行调度不同，CPU资源分配给短请求类似于优先处理短流量的数据包，但是一旦在微秒级别的CPU核心上分派了长请求，就没有经济实惠的方法来抢占它。DARC通过对请求的CPU需求进行分析，将CPU资源有效地分配给请求，并只为短请求启用工作保留，限制分配给长请求的资源，从而实现了与Homa、pFabric或HULL类似的权衡。

该文介绍了一些与DARC技术相关的其他DVFS努力和异构改进尾部CPU延迟的方法，包括调整长请求的并行度、提供更多缓存、基于大小分片数据等。与这些优化不同，DARC定义了为给定请求类型配置电源和核心设置的明确目标。在微秒级延迟下，抢占和空闲之间的权衡发生变化，使得非工作保留的内核旁路调度器成为更好的优化解决方案。

8 Conclusion

PAGE 14

这篇论文介绍了一种新的内核旁路操作系统调度器Perséphone，它实现了DARC，一种应用感知的非工作保留策略，可以在重尾工作负载中保持较好的尾延迟。DARC会对请求进行分析，并将核心分配给较短的请求，保证它们不会被长请求阻塞。Perséphone的原型可以处理更高的负载，而且比现有的内核旁路调度器更好地利用了核心。

9 Acknowledgment

我们感谢牧羊人Jonathan Mace以及OSDI和SOSP匿名审稿人对我们宝贵的意见。我们还要感谢匿名的工件评估和委员会CNS-1563873，他们努力复现了我们的结果。Daniel Berger向我们指出了CSCQ和Mor Harchol-Balter的相关工作。各位朋友帮助我们校对了这篇论文，包括Tom Anderson、Adam Belay和Philip Levis。这项工作得到了NSF CNS-1750158、CNS-1513679的部分支持。
