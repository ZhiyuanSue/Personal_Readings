没有下原文就给个链接吧

https://www.usenix.org/system/files/osdi18-cutler.pdf

然后这门课，我还在知乎发现个翻译的老哥，说实在的直接看代码或者英文教程也确实会头痛的，我贴一下

https://www.zhihu.com/column/c_1294282919087964160



# 摘要

使用带有GC的HLL来实现一个宏内核的POSIX接口的内核。然后探索性能表现，实现难度以及可编程性和安全性等等。

使用Go语言的源码分析来避免跑飞



对于花费在Go的HLL特征比如GC上的消耗，大概在13%左右。

用在NGINX上面花费最长的GC相关的停顿大概在115ms

一个NGINX client的请求则花费600ms。

总体而言，相比于C大概多了5%到15%



# 简介

C有一大堆的问题，HLL则有内存安全，类型安全以及线程抽象等等优点。

Go的静态分析可以分析每个系统调用需要多少内存，一旦允许系统调用，那么这个系统调用的分配一定可以成功。（是个好想法，就是不知道中断嵌套怎么整？？？）

反正整篇文章做了这么几个事情

- 实现了小饼干

- 应对内核堆的新方案

- 讨论内核中使用HLL的定性分析是否有帮助

- 衡量性能

- 比较GO和C
  
  

# 相关工作

在此之前有Pilot和Lisp的内核

Mesa缺少了垃圾回收，但是他的继承语言Cedar则有，LISP则存在一个实时的GC

一大堆的研究性的内核是基于高级语言的

性能当然是个问题，但是这些研究性的内核通常关系到新的idea而不是语言问题。



Gopher OS也是一个Go写的操作系统，但是还在早期开发阶段。

其他的也有，但是并不是为了和biscuit一样的目的。

例如Clive是个unikernel，Ethos OS使用C写Kernel然后go用来用户空间编程，目的是安全。gVisor是个用户空间内核。



对于内存回收，没有一个共识说一定要有或者一定没有，比如Rust就觉得效率不高，然后编译器自动释放内存。但是这又导致了多个线程和闭包之间共享数据变得尴尬。

也有人研究过在Linux内核中添加GC，但是他发现内核环境让这个任务非常困难。



内核堆用完的情况

Linux内核堆用完之后，会等待并且重新试几次但是不可能无限等待，否则会死锁。因此Linux内核必须包含从分配错误中recover的代码。



biscuit的内核分配不会挂掉，因为他一开始就分配好了足够多的内存。只不过会等待。



# motivation

为什么选择C

性能挺重要



HLL

好理解

减少buffer overrun，use after free，类型不安全问题。

但是仍然要有成本



# overview

大概介绍了biscuit的框架。（反正都是OS常见的东西，看过一遍算了）

最底下是个垫片shim层，感觉就像是HAL？？？

runtime

中断

多核和同步异步问题

虚拟内存

文件系统

网络栈

限制：没有优先级因为他依赖于go的运行时调度器。以及为一些数量小的内核做了优化，但是没有考虑NUMA情况下的多核行为。没有swap，也没有反向映射（reverse-mapping）

反向映射本身也是个蛮复杂的技术（。。。头一次听说）



# GC

详见另一个文件夹对于GC的阅读





# 避免heap exhaustion
