# 概述

prefetch，由于存储层次以及数据访问模式，变得越来越复杂，以及需要迁移到不同的访问模式。啊，大概就是模仿Deep Learning或者什么人类神经网络这种东西去构建prefetch。（第一印象：又是一篇加了ai的）

# Introduction

之前也有人搞过这个DL for prefetch。但是有几个问题

1、之前弄这个都是很大的模型，但是prefetch本身，作为一个硬件机制，很难给你这么多的资源去搞事情。

2、offline模型

3、存在灾难性遗忘等问题

作者认为学习这个东西和人类大脑的学习很像（废话）

并且从Complementary Learning Systems这样一个认知理论出发，该理论将人类大脑的认知作为一个在线的学习系统，该理论认为避免灾难性遗忘的方式是interleaved replay，交错学习新旧知识，然后，使用一个基于生物启发的Hebbian网络，该网络使用了相比DNN更少的资源，来帮助我们建立prefetch



（从网上抄来的）

hebbian learning并不是一个新的概念，早在1949唐纳德·赫布提出了赫布律（hebb's rules），简单表述为：

我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升……当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。

更通俗的说法为Cells that fire together, wire together，但是其实这种说法并不完整。赫布强调说，神经元"A"必须对神经元"B"的激发“作出了一定贡献”，因此，神经元"A"的激发必须在神经元"B"之先，而不能同时激发。赫布理论中的这一部分研究，后来被称作STDP，表明突触可塑性需要一定的时间延迟。赫布理论可以用于解释“联合学习”（associative learning），在这种学习中，由对神经元的重复刺激，使得神经元之间的突触强度增加。这样的学习方法被称为赫布型学习（Hebbian learning）。

# DL for Prefetching and Limitations

然后作者就喷别人做的差，他说，他要做成online，资源使用量很低，准确度也很高的prefetch

## Overheads of DL-based Prefetching

说LSTM的那个，因为并行度不高（确实如此）于是花的时间比较多，>60us

然后用了1GB资源，作者压缩了什么padding什么的，于是到了1mb

反正一句话，除了上模拟器，屁用没有

## Difficulty of Online Prefetch Learning

最大的难点在于灾难性遗忘，大概就是，对于prefetch，其模式可能发生变化（比如运行不同的程序，他的内存访问差别会非常大）

有的人就是将新的经验和旧的经验混合起来扔给他去训练，但是，这么说吧，online不能这样搞

作者做了个实验证实这件事情，大概就是先按照某个模式单独训练一个LSTM，再用这个LSTM，迁移到另一个模式当中去，再回去测两个模式，结果确实发现了旧模式陡降的准确率。他确实在某些模式里面回升了准确率，但是，始终非常低

# Hippocampal-Neocortical Inspired Prefetching

使用了CLS理论中的大脑架构，两个部分互相学习：新皮层和海马体

新皮层记忆的慢，比如内存访问模式背后的规则，而海马体记忆的快，比如新的访问模式，将每种访问模式都单独用一种压缩格式存储起来

然后也用了hebbian network来减少资源的使用率



## 克服计算资源大的缺点

使用hebbian network，一个是更新需要的操作很少，第二个是链接比较稀疏，不像全连接的DNN。另外，就像LSTM一样，我们的网络也用一个循环状态来捕捉串行存储器

比起LSTM，存储空间少了3倍，而操作则少了将近一个数量级an order of magnitude。

为了证明这一点，作者做了几个实验，表明确实计算资源更少了。

## 克服灾难性遗忘

他就是说，用海马体中存储的记忆来进行replay，从而减轻灾难性遗忘，于是作者重复性做了之前的实验，但是加上了replay就好很多，虽然仍然会下降但是不会陡然下降，然后呢，最终会回到之前的水平。

# Target Systems for Online Prefetching

包括两个系统，一个是disaggregate，听上去是分布式系统，通过一个switch连接起来，一个CPU-GPU，这俩的差别在于，CPU一次只中断一个page fault，但是GPU会中断好几个

另一个差别在于，他们获取信息并进行prefetch的地方不同，对于CPU-GPU系统，这是一个集中统一决策的，但是分布式系统则是独立进行prefetch决策的。

这俩看上去各有优势，对于CPU-GPU系统，可以获得全局视野，从而有更好的优化策略

而对于分布式系统，由于每个prefetcher单独工作，网络必须足够小来学习对应的模式，他必然对于某些特定模式的优化有更好的结果。



# 未来的改进

计算实例

在每个prefetcher的实例中都进行计算，这件事情本身没有必要且资源消耗量很大。

因此可以按照已有的模型进行迁移学习。在数据集上面测试一次，然后针对miss率高的数据多训练。

一些训练策略比如随机训练一个数据，可能错过对模型很关键的数据

一个办法是使用置信区间去筛选数据，另一个办法是避免在学的很好的数据上面继续学习
